{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.14/04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "import math\n",
    "# Colors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import AutoMinorLocator, MultipleLocator\n",
    "from root_numpy import root2array, tree2array\n",
    "from root_numpy import testdata, fill_hist\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (recall_score,  precision_score, f1_score, roc_auc_score, precision_recall_curve,\n",
    "                             make_scorer, confusion_matrix, accuracy_score, roc_curve)\n",
    "from keras import backend as K\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous Analysis\n",
    "\n",
    "Checking amount of signal and background events in all of the configurations formed by region, tag and signal type.\n",
    "\n",
    "#### Add new column with signal label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the row sample is 'Xtohh1000' or 'Xtohh2000', then the new columns will have a 1 in this row.\n",
    "def classifier(row):\n",
    "    if row['sample'] == 'Xtohh1000':\n",
    "        return 1\n",
    "    #else if row['sample'] == 'Xtohh2000':\n",
    "    #    return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows different of data samples\n",
    "# Select rows on the SR_1tag region\n",
    "def sel_df(df, region):\n",
    "    df = df[(df['sample']!='data') & (df['m_region']==region)]\n",
    "    df[\"signal\"] = df.apply(classifier, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_configs():\n",
    "    print('%-15s%-10s%-10s%-10s%-10s' % (\"Region\", \"Xtohh\", \"Signal\", \"Bkg\", \"Data\"))\n",
    "    for sig in [1000,2000]:\n",
    "        rfile = ROOT.TFile(\"/home/andrea/Escritorio/CERN data/Try3/all_\"+str(sig)+\".root\")\n",
    "        intree = rfile.Get(\"Nominal\")\n",
    "        array = tree2array(intree)\n",
    "        df = pd.DataFrame(array)\n",
    "        for reg in np.unique(df['m_region'].values):\n",
    "            df2 = df[(df['sample']=='data') & (df['m_region']==reg)]\n",
    "            data = df2['sample'].value_counts().values[0]\n",
    "            df_aux = sel_df(df, reg)\n",
    "            bkg = df_aux[\"signal\"].value_counts(sort=False).values[0]\n",
    "            signal = df_aux[\"signal\"].value_counts(sort=False).values[1]\n",
    "            print('%-15s%-10i%-10i%-10i%-10i' % (reg, sig, signal, bkg, data))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region         Xtohh     Signal    Bkg       Data      \n",
      "PreSel_0tag    1000      2550      98061     713       \n",
      "PreSel_1tag    1000      4681      16467     130       \n",
      "PreSel_2tag    1000      4343      995       6         \n",
      "QCDCR_0tag     1000      557       38603     279       \n",
      "QCDCR_1tag     1000      1128      7205      49        \n",
      "QCDCR_2tag     1000      1166      556       5         \n",
      "SR_0tag        1000      1993      59458     434       \n",
      "SR_1tag        1000      3553      9262      81        \n",
      "SR_2tag        1000      3177      439       1         \n",
      "PreSel_0tag    2000      2867      98061     713       \n",
      "PreSel_1tag    2000      11507     16467     130       \n",
      "PreSel_2tag    2000      13720     995       6         \n",
      "QCDCR_0tag     2000      544       38603     279       \n",
      "QCDCR_1tag     2000      2152      7205      49        \n",
      "QCDCR_2tag     2000      2271      556       5         \n",
      "SR_0tag        2000      2323      59458     434       \n",
      "SR_1tag        2000      9355      9262      81        \n",
      "SR_2tag        2000      11449     439       1         \n"
     ]
    }
   ],
   "source": [
    "print_configs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import ROOT file\n",
    "\n",
    "You can either import a file which includes both Xtohh1000 and Xtohh2000 signal events, but their samples must be different or import just the file which includes one of the signals and the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfile = ROOT.TFile(\"/home/andrea/Escritorio/CERN data/Try3/all_1000.root\")\n",
    "intree = rfile.Get(\"Nominal\")\n",
    "array = tree2array(intree)\n",
    "df = pd.DataFrame(array)\n",
    "df = sel_df(df, \"SR_1tag\")\n",
    "\n",
    "# Delete columns\n",
    "not_cons = ['sample', 'EventNumber', 'm_region', 'm_FJNbtagJets', 'm_FJphi', 'm_FJeta', 'm_DTeta', 'm_DTphi']\n",
    "df.drop(not_cons, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 14804\n",
      "Test size: 2563\n",
      "Signal amount: 3553 , 0.28 %\n",
      "Background amount: 9262 , 0.72 %\n"
     ]
    }
   ],
   "source": [
    "# Features\n",
    "feature_cols = df.columns.values[:-1]\n",
    "\n",
    "X = df.loc[:, feature_cols].values\n",
    "# Targets\n",
    "y = df['signal'].values\n",
    "\n",
    "#from imblearn.over_sampling import RandomOverSampler\n",
    "#ros = RandomOverSampler(random_state=0)\n",
    "#X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "#https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Training size:\",X_train.shape[0])\n",
    "print(\"Test size:\", X_test.shape[0])\n",
    "values, counts = np.unique(y, return_counts=True)\n",
    "print(\"Signal amount:\", counts[1],\",\", round(counts[1]/y.shape[0], 2),\"%\")\n",
    "print(\"Background amount:\", counts[0],\",\", round(counts[0]/y.shape[0], 2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal training events: 7402 , 0.5 %\n",
      "Background training events: 7402 , 0.5 %\n",
      "Signal testing events: 703 , 0.27 %\n",
      "Background testing events: 1860 , 0.73 %\n"
     ]
    }
   ],
   "source": [
    "values_s, count_s = np.unique(y_train, return_counts=True)\n",
    "print(\"Signal training events:\", count_s[1],\",\", round(count_s[1]/X_train.shape[0], 2),\"%\")\n",
    "print(\"Background training events:\", count_s[0],\",\", round(count_s[0]/X_train.shape[0],2),\"%\")\n",
    "values_b, count_b = np.unique(y_test, return_counts=True)\n",
    "print(\"Signal testing events:\", count_b[1],\",\", round(count_b[1]/X_test.shape[0],2),\"%\")\n",
    "print(\"Background testing events:\", count_b[0],\",\", round(count_b[0]/X_test.shape[0],2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom metric: F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_(y_true, y_pred):\n",
    "    def recall_(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision_(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision_(y_true, y_pred)\n",
    "    recall = recall_(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(100, activation='relu', kernel_initializer='uniform', input_dim=11))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(100, activation='relu', kernel_initializer='uniform'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "#Third  Hidden Layer\n",
    "classifier.add(Dense(100, activation='relu', kernel_initializer='uniform'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "#Fourth Hidden Layer\n",
    "classifier.add(Dense(100, activation='relu', kernel_initializer='uniform'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "#Fifth Hidden Layer\n",
    "classifier.add(Dense(100, activation='relu', kernel_initializer='uniform'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =[f1_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14804/14804 [==============================] - 3s 226us/step - loss: 0.6679 - f1_: 0.6562\n",
      "Epoch 2/200\n",
      "14804/14804 [==============================] - 2s 121us/step - loss: 0.6392 - f1_: 0.6869\n",
      "Epoch 3/200\n",
      "14804/14804 [==============================] - 2s 103us/step - loss: 0.6349 - f1_: 0.6885\n",
      "Epoch 4/200\n",
      "14804/14804 [==============================] - 2s 103us/step - loss: 0.6136 - f1_: 0.6924\n",
      "Epoch 5/200\n",
      "14804/14804 [==============================] - 2s 104us/step - loss: 0.5937 - f1_: 0.7044\n",
      "Epoch 6/200\n",
      "14804/14804 [==============================] - 2s 106us/step - loss: 0.5674 - f1_: 0.7304\n",
      "Epoch 7/200\n",
      "14804/14804 [==============================] - 2s 120us/step - loss: 0.5732 - f1_: 0.7269\n",
      "Epoch 8/200\n",
      "14804/14804 [==============================] - 2s 110us/step - loss: 0.5677 - f1_: 0.7340\n",
      "Epoch 9/200\n",
      "14804/14804 [==============================] - 2s 114us/step - loss: 0.5534 - f1_: 0.7342\n",
      "Epoch 10/200\n",
      "14804/14804 [==============================] - 2s 112us/step - loss: 0.5521 - f1_: 0.7337\n",
      "Epoch 11/200\n",
      "14804/14804 [==============================] - 2s 111us/step - loss: 0.5440 - f1_: 0.7416\n",
      "Epoch 12/200\n",
      "14804/14804 [==============================] - 2s 110us/step - loss: 0.5470 - f1_: 0.7375\n",
      "Epoch 13/200\n",
      "14804/14804 [==============================] - 2s 120us/step - loss: 0.5371 - f1_: 0.7540\n",
      "Epoch 14/200\n",
      "14804/14804 [==============================] - 2s 155us/step - loss: 0.5305 - f1_: 0.7541\n",
      "Epoch 15/200\n",
      "14804/14804 [==============================] - 3s 186us/step - loss: 0.5306 - f1_: 0.7530\n",
      "Epoch 16/200\n",
      "14804/14804 [==============================] - 2s 131us/step - loss: 0.5336 - f1_: 0.7479\n",
      "Epoch 17/200\n",
      "14804/14804 [==============================] - 2s 127us/step - loss: 0.5529 - f1_: 0.7379\n",
      "Epoch 18/200\n",
      "14804/14804 [==============================] - 2s 129us/step - loss: 0.5365 - f1_: 0.7534\n",
      "Epoch 19/200\n",
      "14804/14804 [==============================] - 2s 117us/step - loss: 0.5431 - f1_: 0.7515\n",
      "Epoch 20/200\n",
      "14804/14804 [==============================] - 2s 113us/step - loss: 0.5372 - f1_: 0.7527\n",
      "Epoch 21/200\n",
      "14804/14804 [==============================] - 2s 120us/step - loss: 0.5333 - f1_: 0.7568\n",
      "Epoch 22/200\n",
      "14804/14804 [==============================] - 2s 128us/step - loss: 0.5328 - f1_: 0.7574\n",
      "Epoch 23/200\n",
      "14804/14804 [==============================] - 2s 126us/step - loss: 0.5267 - f1_: 0.7603\n",
      "Epoch 24/200\n",
      "14804/14804 [==============================] - 2s 112us/step - loss: 0.5275 - f1_: 0.7617\n",
      "Epoch 25/200\n",
      "14804/14804 [==============================] - 2s 116us/step - loss: 0.5417 - f1_: 0.7501\n",
      "Epoch 26/200\n",
      "14804/14804 [==============================] - 2s 124us/step - loss: 0.5266 - f1_: 0.7573\n",
      "Epoch 27/200\n",
      "14804/14804 [==============================] - 2s 128us/step - loss: 0.5282 - f1_: 0.7587\n",
      "Epoch 28/200\n",
      "14804/14804 [==============================] - 2s 116us/step - loss: 0.5340 - f1_: 0.7545\n",
      "Epoch 29/200\n",
      "14804/14804 [==============================] - 2s 120us/step - loss: 0.5260 - f1_: 0.7641\n",
      "Epoch 30/200\n",
      "14804/14804 [==============================] - 2s 117us/step - loss: 0.5265 - f1_: 0.7622\n",
      "Epoch 31/200\n",
      "14804/14804 [==============================] - 2s 127us/step - loss: 0.5249 - f1_: 0.7637\n",
      "Epoch 32/200\n",
      "14804/14804 [==============================] - 2s 146us/step - loss: 0.5237 - f1_: 0.7660\n",
      "Epoch 33/200\n",
      "14804/14804 [==============================] - 2s 136us/step - loss: 0.5248 - f1_: 0.7625\n",
      "Epoch 34/200\n",
      "14804/14804 [==============================] - 2s 132us/step - loss: 0.5226 - f1_: 0.7660\n",
      "Epoch 35/200\n",
      "14804/14804 [==============================] - 2s 143us/step - loss: 0.5216 - f1_: 0.7645\n",
      "Epoch 36/200\n",
      "14804/14804 [==============================] - 2s 129us/step - loss: 0.5218 - f1_: 0.7600\n",
      "Epoch 37/200\n",
      "14804/14804 [==============================] - 2s 120us/step - loss: 0.5331 - f1_: 0.7511\n",
      "Epoch 38/200\n",
      "14804/14804 [==============================] - 2s 135us/step - loss: 0.5254 - f1_: 0.7609\n",
      "Epoch 39/200\n",
      "14804/14804 [==============================] - 2s 137us/step - loss: 0.5274 - f1_: 0.7672\n",
      "Epoch 40/200\n",
      "14804/14804 [==============================] - 2s 126us/step - loss: 0.5208 - f1_: 0.7614\n",
      "Epoch 41/200\n",
      "14804/14804 [==============================] - 2s 118us/step - loss: 0.5365 - f1_: 0.7474\n",
      "Epoch 42/200\n",
      "14804/14804 [==============================] - 2s 117us/step - loss: 0.5285 - f1_: 0.7545\n",
      "Epoch 43/200\n",
      "14804/14804 [==============================] - 2s 126us/step - loss: 0.5448 - f1_: 0.7451\n",
      "Epoch 44/200\n",
      "14804/14804 [==============================] - 2s 128us/step - loss: 0.5248 - f1_: 0.7575\n",
      "Epoch 45/200\n",
      "14804/14804 [==============================] - 2s 119us/step - loss: 0.5402 - f1_: 0.7505\n",
      "Epoch 46/200\n",
      "14804/14804 [==============================] - 2s 120us/step - loss: 0.5310 - f1_: 0.7559\n",
      "Epoch 47/200\n",
      "14804/14804 [==============================] - 2s 122us/step - loss: 0.5335 - f1_: 0.7502\n",
      "Epoch 48/200\n",
      "14804/14804 [==============================] - 2s 129us/step - loss: 0.5404 - f1_: 0.7464\n",
      "Epoch 49/200\n",
      "14804/14804 [==============================] - 2s 120us/step - loss: 0.5537 - f1_: 0.7352\n",
      "Epoch 50/200\n",
      "14804/14804 [==============================] - 2s 117us/step - loss: 0.5934 - f1_: 0.7330\n",
      "Epoch 51/200\n",
      "14804/14804 [==============================] - 2s 116us/step - loss: 0.5416 - f1_: 0.7503\n",
      "Epoch 52/200\n",
      "14804/14804 [==============================] - 2s 131us/step - loss: 0.5410 - f1_: 0.7455\n",
      "Epoch 53/200\n",
      "14804/14804 [==============================] - 2s 130us/step - loss: 0.5525 - f1_: 0.7322\n",
      "Epoch 54/200\n",
      "14804/14804 [==============================] - 4s 253us/step - loss: 0.5744 - f1_: 0.7022\n",
      "Epoch 55/200\n",
      "14804/14804 [==============================] - 3s 212us/step - loss: 0.5487 - f1_: 0.7476\n",
      "Epoch 56/200\n",
      "14804/14804 [==============================] - 2s 149us/step - loss: 0.5348 - f1_: 0.7549\n",
      "Epoch 57/200\n",
      "14804/14804 [==============================] - 2s 132us/step - loss: 0.5340 - f1_: 0.7536\n",
      "Epoch 58/200\n",
      "14804/14804 [==============================] - 2s 124us/step - loss: 0.5297 - f1_: 0.7563\n",
      "Epoch 59/200\n",
      "14804/14804 [==============================] - 2s 110us/step - loss: 0.5422 - f1_: 0.7408\n",
      "Epoch 60/200\n",
      "14804/14804 [==============================] - 2s 112us/step - loss: 0.5333 - f1_: 0.7569\n",
      "Epoch 61/200\n",
      "14804/14804 [==============================] - 2s 125us/step - loss: 0.5549 - f1_: 0.7198\n",
      "Epoch 62/200\n",
      "14804/14804 [==============================] - 2s 124us/step - loss: 0.5368 - f1_: 0.7514\n",
      "Epoch 63/200\n",
      "14804/14804 [==============================] - 2s 112us/step - loss: 0.5470 - f1_: 0.7453\n",
      "Epoch 64/200\n",
      "14804/14804 [==============================] - 2s 113us/step - loss: 0.5336 - f1_: 0.7463\n",
      "Epoch 65/200\n",
      "14804/14804 [==============================] - 2s 126us/step - loss: 0.5650 - f1_: 0.7104\n",
      "Epoch 66/200\n",
      "14804/14804 [==============================] - 3s 172us/step - loss: 0.5445 - f1_: 0.7479\n",
      "Epoch 67/200\n",
      "14804/14804 [==============================] - 5s 325us/step - loss: 0.5397 - f1_: 0.7526\n",
      "Epoch 68/200\n",
      "14804/14804 [==============================] - 3s 216us/step - loss: 0.5331 - f1_: 0.7635\n",
      "Epoch 69/200\n",
      "14804/14804 [==============================] - 2s 148us/step - loss: 0.5428 - f1_: 0.7399\n",
      "Epoch 70/200\n",
      "14804/14804 [==============================] - 2s 155us/step - loss: 0.5310 - f1_: 0.7551\n",
      "Epoch 71/200\n",
      "14804/14804 [==============================] - 3s 195us/step - loss: 0.5476 - f1_: 0.7278\n",
      "Epoch 72/200\n",
      "14804/14804 [==============================] - 2s 158us/step - loss: 0.5308 - f1_: 0.7546\n",
      "Epoch 73/200\n",
      "14804/14804 [==============================] - 2s 130us/step - loss: 0.5275 - f1_: 0.7570\n",
      "Epoch 74/200\n",
      "14804/14804 [==============================] - 2s 136us/step - loss: 0.5239 - f1_: 0.7633\n",
      "Epoch 75/200\n",
      "14804/14804 [==============================] - 2s 139us/step - loss: 0.5305 - f1_: 0.7593\n",
      "Epoch 76/200\n",
      "14804/14804 [==============================] - 2s 164us/step - loss: 0.5415 - f1_: 0.7516\n",
      "Epoch 77/200\n",
      "14804/14804 [==============================] - 2s 142us/step - loss: 0.5535 - f1_: 0.7444\n",
      "Epoch 78/200\n",
      "14804/14804 [==============================] - 4s 242us/step - loss: 0.5280 - f1_: 0.7584\n",
      "Epoch 79/200\n",
      "14804/14804 [==============================] - 3s 233us/step - loss: 0.5209 - f1_: 0.7639\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14804/14804 [==============================] - 3s 196us/step - loss: 0.5261 - f1_: 0.7586\n",
      "Epoch 81/200\n",
      "14804/14804 [==============================] - 4s 282us/step - loss: 0.5287 - f1_: 0.7552\n",
      "Epoch 82/200\n",
      "14804/14804 [==============================] - 3s 225us/step - loss: 0.5329 - f1_: 0.7564\n",
      "Epoch 83/200\n",
      "14804/14804 [==============================] - 2s 169us/step - loss: 0.5231 - f1_: 0.7658\n",
      "Epoch 84/200\n",
      "14804/14804 [==============================] - 3s 197us/step - loss: 0.5317 - f1_: 0.7560\n",
      "Epoch 85/200\n",
      "14804/14804 [==============================] - 3s 169us/step - loss: 0.5254 - f1_: 0.7639\n",
      "Epoch 86/200\n",
      "14804/14804 [==============================] - 2s 149us/step - loss: 0.5504 - f1_: 0.7392\n",
      "Epoch 87/200\n",
      "14804/14804 [==============================] - 3s 179us/step - loss: 0.5480 - f1_: 0.7321\n",
      "Epoch 88/200\n",
      "14804/14804 [==============================] - 3s 177us/step - loss: 0.5325 - f1_: 0.7550\n",
      "Epoch 89/200\n",
      "14804/14804 [==============================] - 2s 146us/step - loss: 0.5561 - f1_: 0.7221\n",
      "Epoch 90/200\n",
      "14804/14804 [==============================] - 3s 176us/step - loss: 0.5620 - f1_: 0.7233\n",
      "Epoch 91/200\n",
      "14804/14804 [==============================] - 3s 203us/step - loss: 0.5509 - f1_: 0.7433\n",
      "Epoch 92/200\n",
      "14804/14804 [==============================] - 2s 150us/step - loss: 0.5323 - f1_: 0.7566\n",
      "Epoch 93/200\n",
      "14804/14804 [==============================] - 2s 166us/step - loss: 0.5275 - f1_: 0.7605\n",
      "Epoch 94/200\n",
      "14804/14804 [==============================] - 3s 197us/step - loss: 0.5432 - f1_: 0.7468\n",
      "Epoch 95/200\n",
      "14804/14804 [==============================] - 2s 152us/step - loss: 0.5397 - f1_: 0.7434\n",
      "Epoch 96/200\n",
      "14804/14804 [==============================] - 2s 145us/step - loss: 0.5797 - f1_: 0.7294\n",
      "Epoch 97/200\n",
      "14804/14804 [==============================] - 2s 135us/step - loss: 0.5549 - f1_: 0.7475\n",
      "Epoch 98/200\n",
      "14804/14804 [==============================] - 2s 139us/step - loss: 0.5379 - f1_: 0.7632\n",
      "Epoch 99/200\n",
      "14804/14804 [==============================] - 2s 150us/step - loss: 0.5207 - f1_: 0.7607\n",
      "Epoch 100/200\n",
      "14804/14804 [==============================] - 3s 201us/step - loss: 0.5222 - f1_: 0.7693\n",
      "Epoch 101/200\n",
      "14804/14804 [==============================] - 4s 261us/step - loss: 0.5266 - f1_: 0.7623\n",
      "Epoch 102/200\n",
      "14804/14804 [==============================] - 3s 213us/step - loss: 0.5307 - f1_: 0.7539\n",
      "Epoch 103/200\n",
      "14804/14804 [==============================] - 2s 136us/step - loss: 0.5452 - f1_: 0.7450\n",
      "Epoch 104/200\n",
      "14804/14804 [==============================] - 2s 134us/step - loss: 0.5485 - f1_: 0.7434\n",
      "Epoch 105/200\n",
      "14804/14804 [==============================] - 2s 128us/step - loss: 0.5795 - f1_: 0.7019\n",
      "Epoch 106/200\n",
      "14804/14804 [==============================] - 2s 123us/step - loss: 0.5666 - f1_: 0.7356\n",
      "Epoch 107/200\n",
      "14804/14804 [==============================] - 3s 174us/step - loss: 0.5406 - f1_: 0.7549\n",
      "Epoch 108/200\n",
      "14804/14804 [==============================] - 2s 150us/step - loss: 0.5299 - f1_: 0.7548\n",
      "Epoch 109/200\n",
      "14804/14804 [==============================] - 2s 133us/step - loss: 0.5322 - f1_: 0.7494\n",
      "Epoch 110/200\n",
      "14804/14804 [==============================] - 2s 133us/step - loss: 0.5204 - f1_: 0.7654\n",
      "Epoch 111/200\n",
      "14804/14804 [==============================] - 2s 128us/step - loss: 0.5291 - f1_: 0.7606\n",
      "Epoch 112/200\n",
      "14804/14804 [==============================] - 3s 214us/step - loss: 0.5256 - f1_: 0.7689\n",
      "Epoch 113/200\n",
      "14804/14804 [==============================] - 3s 233us/step - loss: 0.5282 - f1_: 0.7604\n",
      "Epoch 114/200\n",
      "14804/14804 [==============================] - 3s 209us/step - loss: 0.5216 - f1_: 0.7714\n",
      "Epoch 115/200\n",
      "14804/14804 [==============================] - 3s 217us/step - loss: 0.5324 - f1_: 0.7602\n",
      "Epoch 116/200\n",
      "14804/14804 [==============================] - 4s 282us/step - loss: 0.5319 - f1_: 0.7561\n",
      "Epoch 117/200\n",
      "14804/14804 [==============================] - 2s 132us/step - loss: 0.5190 - f1_: 0.7695\n",
      "Epoch 118/200\n",
      "14804/14804 [==============================] - 2s 131us/step - loss: 0.5301 - f1_: 0.7669\n",
      "Epoch 119/200\n",
      "14804/14804 [==============================] - 2s 120us/step - loss: 0.5315 - f1_: 0.7572\n",
      "Epoch 120/200\n",
      "14804/14804 [==============================] - 2s 143us/step - loss: 0.5401 - f1_: 0.7563\n",
      "Epoch 121/200\n",
      "14804/14804 [==============================] - 2s 136us/step - loss: 0.5366 - f1_: 0.7540\n",
      "Epoch 122/200\n",
      "14804/14804 [==============================] - 2s 136us/step - loss: 0.5280 - f1_: 0.7604\n",
      "Epoch 123/200\n",
      "14804/14804 [==============================] - 3s 232us/step - loss: 0.5266 - f1_: 0.7613\n",
      "Epoch 124/200\n",
      "14804/14804 [==============================] - 3s 177us/step - loss: 0.5333 - f1_: 0.7641\n",
      "Epoch 125/200\n",
      "14804/14804 [==============================] - 2s 161us/step - loss: 0.5384 - f1_: 0.7645\n",
      "Epoch 126/200\n",
      "14804/14804 [==============================] - 2s 129us/step - loss: 0.5264 - f1_: 0.7685\n",
      "Epoch 127/200\n",
      "14804/14804 [==============================] - 2s 131us/step - loss: 0.5284 - f1_: 0.7708\n",
      "Epoch 128/200\n",
      "14804/14804 [==============================] - 2s 120us/step - loss: 0.5481 - f1_: 0.7547\n",
      "Epoch 129/200\n",
      "14804/14804 [==============================] - 2s 123us/step - loss: 0.5485 - f1_: 0.7617\n",
      "Epoch 130/200\n",
      "14804/14804 [==============================] - 2s 129us/step - loss: 0.5362 - f1_: 0.7619\n",
      "Epoch 131/200\n",
      "14804/14804 [==============================] - 2s 129us/step - loss: 0.5720 - f1_: 0.7012\n",
      "Epoch 132/200\n",
      "14804/14804 [==============================] - 2s 129us/step - loss: 0.6302 - f1_: 0.6366\n",
      "Epoch 133/200\n",
      "14804/14804 [==============================] - 2s 118us/step - loss: 0.6082 - f1_: 0.7191\n",
      "Epoch 134/200\n",
      "14804/14804 [==============================] - 2s 125us/step - loss: 0.5776 - f1_: 0.7347\n",
      "Epoch 135/200\n",
      "14804/14804 [==============================] - 2s 128us/step - loss: 0.5834 - f1_: 0.7302\n",
      "Epoch 136/200\n",
      "14804/14804 [==============================] - 2s 122us/step - loss: 0.5732 - f1_: 0.7424\n",
      "Epoch 137/200\n",
      "14804/14804 [==============================] - 2s 124us/step - loss: 0.5556 - f1_: 0.7450\n",
      "Epoch 138/200\n",
      "14804/14804 [==============================] - 2s 131us/step - loss: 0.5371 - f1_: 0.7536\n",
      "Epoch 139/200\n",
      "14804/14804 [==============================] - 2s 145us/step - loss: 0.5439 - f1_: 0.7574\n",
      "Epoch 140/200\n",
      "14804/14804 [==============================] - 2s 135us/step - loss: 0.5316 - f1_: 0.7577\n",
      "Epoch 141/200\n",
      "14804/14804 [==============================] - 2s 118us/step - loss: 0.5362 - f1_: 0.7564\n",
      "Epoch 142/200\n",
      "14804/14804 [==============================] - 2s 135us/step - loss: 0.5432 - f1_: 0.7597\n",
      "Epoch 143/200\n",
      "14804/14804 [==============================] - 2s 131us/step - loss: 0.5304 - f1_: 0.7599\n",
      "Epoch 144/200\n",
      "14804/14804 [==============================] - 2s 132us/step - loss: 0.5143 - f1_: 0.7717\n",
      "Epoch 145/200\n",
      "14804/14804 [==============================] - 2s 117us/step - loss: 0.5377 - f1_: 0.7614\n",
      "Epoch 146/200\n",
      "14804/14804 [==============================] - 2s 126us/step - loss: 0.5234 - f1_: 0.7642\n",
      "Epoch 147/200\n",
      "14804/14804 [==============================] - 2s 129us/step - loss: 0.5103 - f1_: 0.7756\n",
      "Epoch 148/200\n",
      "14804/14804 [==============================] - 2s 135us/step - loss: 0.5209 - f1_: 0.7649\n",
      "Epoch 149/200\n",
      "14804/14804 [==============================] - 2s 117us/step - loss: 0.5219 - f1_: 0.7706\n",
      "Epoch 150/200\n",
      "14804/14804 [==============================] - 2s 116us/step - loss: 0.5095 - f1_: 0.7691\n",
      "Epoch 151/200\n",
      "14804/14804 [==============================] - 2s 124us/step - loss: 0.5104 - f1_: 0.7742\n",
      "Epoch 152/200\n",
      "14804/14804 [==============================] - 2s 136us/step - loss: 0.5146 - f1_: 0.7696\n",
      "Epoch 153/200\n",
      "14804/14804 [==============================] - 3s 193us/step - loss: 0.5318 - f1_: 0.7619\n",
      "Epoch 154/200\n",
      "14804/14804 [==============================] - 4s 247us/step - loss: 0.5438 - f1_: 0.7417\n",
      "Epoch 155/200\n",
      "14804/14804 [==============================] - 3s 191us/step - loss: 0.5319 - f1_: 0.7630\n",
      "Epoch 156/200\n",
      "14804/14804 [==============================] - 2s 157us/step - loss: 0.5393 - f1_: 0.7543\n",
      "Epoch 157/200\n",
      "14804/14804 [==============================] - 2s 125us/step - loss: 0.5237 - f1_: 0.7678\n",
      "Epoch 158/200\n",
      "14804/14804 [==============================] - 2s 118us/step - loss: 0.5218 - f1_: 0.7658\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14804/14804 [==============================] - 2s 119us/step - loss: 0.5312 - f1_: 0.7567\n",
      "Epoch 160/200\n",
      "14804/14804 [==============================] - 2s 130us/step - loss: 0.5211 - f1_: 0.7693\n",
      "Epoch 161/200\n",
      "14804/14804 [==============================] - 2s 130us/step - loss: 0.5264 - f1_: 0.7706\n",
      "Epoch 162/200\n",
      "14804/14804 [==============================] - 2s 113us/step - loss: 0.5146 - f1_: 0.7726\n",
      "Epoch 163/200\n",
      "14804/14804 [==============================] - 2s 115us/step - loss: 0.5190 - f1_: 0.7693\n",
      "Epoch 164/200\n",
      "14804/14804 [==============================] - 2s 126us/step - loss: 0.5077 - f1_: 0.7740\n",
      "Epoch 165/200\n",
      "14804/14804 [==============================] - 2s 129us/step - loss: 0.5072 - f1_: 0.7740\n",
      "Epoch 166/200\n",
      "14804/14804 [==============================] - 2s 119us/step - loss: 0.5115 - f1_: 0.7701\n",
      "Epoch 167/200\n",
      "14804/14804 [==============================] - 2s 115us/step - loss: 0.5017 - f1_: 0.7804\n",
      "Epoch 168/200\n",
      "14804/14804 [==============================] - 2s 119us/step - loss: 0.5103 - f1_: 0.7753\n",
      "Epoch 169/200\n",
      "14804/14804 [==============================] - 2s 136us/step - loss: 0.5056 - f1_: 0.7784\n",
      "Epoch 170/200\n",
      "14804/14804 [==============================] - 2s 131us/step - loss: 0.5065 - f1_: 0.7743\n",
      "Epoch 171/200\n",
      "14804/14804 [==============================] - 2s 119us/step - loss: 0.5072 - f1_: 0.7697\n",
      "Epoch 172/200\n",
      "14804/14804 [==============================] - 2s 117us/step - loss: 0.5033 - f1_: 0.7827\n",
      "Epoch 173/200\n",
      "14804/14804 [==============================] - 2s 128us/step - loss: 0.5227 - f1_: 0.7730\n",
      "Epoch 174/200\n",
      "14804/14804 [==============================] - 2s 131us/step - loss: 0.5171 - f1_: 0.7588\n",
      "Epoch 175/200\n",
      "14804/14804 [==============================] - 2s 127us/step - loss: 0.5144 - f1_: 0.7743\n",
      "Epoch 176/200\n",
      "14804/14804 [==============================] - 2s 126us/step - loss: 0.5084 - f1_: 0.7707\n",
      "Epoch 177/200\n",
      "14804/14804 [==============================] - 2s 148us/step - loss: 0.5140 - f1_: 0.7556\n",
      "Epoch 178/200\n",
      "14804/14804 [==============================] - 2s 156us/step - loss: 0.5123 - f1_: 0.7564\n",
      "Epoch 179/200\n",
      "14804/14804 [==============================] - 2s 138us/step - loss: 0.5310 - f1_: 0.7479\n",
      "Epoch 180/200\n",
      "14804/14804 [==============================] - 2s 143us/step - loss: 0.5225 - f1_: 0.7565\n",
      "Epoch 181/200\n",
      "14804/14804 [==============================] - 2s 133us/step - loss: 0.5273 - f1_: 0.7491\n",
      "Epoch 182/200\n",
      "14804/14804 [==============================] - 2s 125us/step - loss: 0.5252 - f1_: 0.7626\n",
      "Epoch 183/200\n",
      "14804/14804 [==============================] - 2s 109us/step - loss: 0.5107 - f1_: 0.7711\n",
      "Epoch 184/200\n",
      "14804/14804 [==============================] - 2s 116us/step - loss: 0.5092 - f1_: 0.7681\n",
      "Epoch 185/200\n",
      "14804/14804 [==============================] - 2s 118us/step - loss: 0.5169 - f1_: 0.7467\n",
      "Epoch 186/200\n",
      "14804/14804 [==============================] - 2s 125us/step - loss: 0.5085 - f1_: 0.7648\n",
      "Epoch 187/200\n",
      "14804/14804 [==============================] - 2s 125us/step - loss: 0.5106 - f1_: 0.7665\n",
      "Epoch 188/200\n",
      "14804/14804 [==============================] - 2s 110us/step - loss: 0.5128 - f1_: 0.7488\n",
      "Epoch 189/200\n",
      "14804/14804 [==============================] - 2s 112us/step - loss: 0.5129 - f1_: 0.7633\n",
      "Epoch 190/200\n",
      "14804/14804 [==============================] - 2s 125us/step - loss: 0.5028 - f1_: 0.7763\n",
      "Epoch 191/200\n",
      "14804/14804 [==============================] - 2s 125us/step - loss: 0.5076 - f1_: 0.7713\n",
      "Epoch 192/200\n",
      "14804/14804 [==============================] - 2s 117us/step - loss: 0.5164 - f1_: 0.7597\n",
      "Epoch 193/200\n",
      "14804/14804 [==============================] - 2s 126us/step - loss: 0.5266 - f1_: 0.7472\n",
      "Epoch 194/200\n",
      "14804/14804 [==============================] - 2s 165us/step - loss: 0.5159 - f1_: 0.7581\n",
      "Epoch 195/200\n",
      "14804/14804 [==============================] - 2s 147us/step - loss: 0.5605 - f1_: 0.7344\n",
      "Epoch 196/200\n",
      "14804/14804 [==============================] - 2s 120us/step - loss: 0.5779 - f1_: 0.7304\n",
      "Epoch 197/200\n",
      "14804/14804 [==============================] - 2s 120us/step - loss: 0.5607 - f1_: 0.7404\n",
      "Epoch 198/200\n",
      "14804/14804 [==============================] - 2s 127us/step - loss: 0.6198 - f1_: 0.6819\n",
      "Epoch 199/200\n",
      "14804/14804 [==============================] - 2s 128us/step - loss: 0.5915 - f1_: 0.6421\n",
      "Epoch 200/200\n",
      "14804/14804 [==============================] - 2s 119us/step - loss: 0.5419 - f1_: 0.7610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f00b2ac1710>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the data to the training dataset\n",
    "classifier.fit(X_train,y_train, batch_size=50, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181185854785176"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_prob = classifier.predict(X_test)\n",
    "y_pred = (y_pred_prob>0.5)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob, pos_label=1)\n",
    "plt.plot(fpr, tpr)\n",
    "roc_auc_score(y_test, y_pred_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.9231863442389758\n",
      "precision: 0.43703703703703706\n",
      "accuracy: 0.6527506827936013\n"
     ]
    }
   ],
   "source": [
    "r = recall_score(y_test,y_pred)\n",
    "p = precision_score(y_test,y_pred)\n",
    "a = accuracy_score(y_test,y_pred)\n",
    "\n",
    "print(\"recall:\", r)\n",
    "print(\"precision:\", p)\n",
    "print(\"accuracy:\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f00a4589d30>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "plt.plot(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1024  836]\n",
      " [  54  649]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:20]\n",
    "aux = np.concatenate(y_pred[:20])\n",
    "1*aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO:\n",
    "\n",
    "- Ver mtodo de oversampling debido al desbalanceo de los datos. Un mtodo tpico es el SMOTE.\n",
    "- Hacer una tabla resumen de las configuraciones de regin y seal, para generar los modelos de entrenamiento, contar la cantidad de seal y background en cada configuracin.\n",
    "- Usar f1 de HER2 como mtrica de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
