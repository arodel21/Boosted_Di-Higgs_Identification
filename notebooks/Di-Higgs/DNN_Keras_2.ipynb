{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "import math\n",
    "# Colors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.ticker import AutoMinorLocator, MultipleLocator\n",
    "from root_numpy import root2array, tree2array\n",
    "from root_numpy import testdata, fill_hist\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (recall_score,  precision_score, f1_score, roc_auc_score, precision_recall_curve,\n",
    "                             make_scorer, confusion_matrix, accuracy_score, roc_curve)\n",
    "from keras import backend as K\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previous Analysis\n",
    "\n",
    "Checking amount of signal and background events in all of the configurations formed by region, tag and signal type.\n",
    "\n",
    "#### Add new column with signal label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the row sample is 'Xtohh1000' or 'Xtohh2000', then the new columns will have a 1 in this row.\n",
    "def classifier(row):\n",
    "    if row['sample'] == 'Xtohh1000':\n",
    "        return 1\n",
    "    #else if row['sample'] == 'Xtohh2000':\n",
    "    #    return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows different of data samples\n",
    "# Select rows on the SR_1tag region\n",
    "def sel_df(df, region):\n",
    "    df = df[(df['sample']!='data') & (df['m_region']==region)]\n",
    "    df[\"signal\"] = df.apply(classifier, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_configs():\n",
    "    print('%-15s%-10s%-10s%-10s' % (\"Region\", \"Xtohh\", \"Signal\", \"Bkg\"))\n",
    "    for sig in [1000,2000]:\n",
    "        rfile = ROOT.TFile(\"/home/andrea/Escritorio/CERN data/Try3/all_\"+str(sig)+\".root\")\n",
    "        intree = rfile.Get(\"Nominal\")\n",
    "        array = tree2array(intree)\n",
    "        df = pd.DataFrame(array)\n",
    "        for reg in np.unique(df['m_region'].values):\n",
    "            df_aux = sel_df(df, reg)\n",
    "            bkg = df_aux[\"signal\"].value_counts().values[0]\n",
    "            signal = df_aux[\"signal\"].value_counts().values[1]\n",
    "            print('%-15s%-10i%-10i%-10i' % (reg, sig, signal, bkg))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region         Xtohh     Signal    Bkg       \n",
      "PreSel_0tag    1000      2550      98061     \n",
      "PreSel_1tag    1000      4681      16467     \n",
      "PreSel_2tag    1000      995       4343      \n",
      "QCDCR_0tag     1000      557       38603     \n",
      "QCDCR_1tag     1000      1128      7205      \n",
      "QCDCR_2tag     1000      556       1166      \n",
      "SR_0tag        1000      1993      59458     \n",
      "SR_1tag        1000      3553      9262      \n",
      "SR_2tag        1000      439       3177      \n",
      "PreSel_0tag    2000      2867      98061     \n",
      "PreSel_1tag    2000      11507     16467     \n",
      "PreSel_2tag    2000      995       13720     \n",
      "QCDCR_0tag     2000      544       38603     \n",
      "QCDCR_1tag     2000      2152      7205      \n",
      "QCDCR_2tag     2000      556       2271      \n",
      "SR_0tag        2000      2323      59458     \n",
      "SR_1tag        2000      9262      9355      \n",
      "SR_2tag        2000      439       11449     \n"
     ]
    }
   ],
   "source": [
    "print_configs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import ROOT file\n",
    "\n",
    "You can either import a file which includes both Xtohh1000 and Xtohh2000 signal events, but their samples must be different or import just the file which includes one of the signals and the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfile = ROOT.TFile(\"/home/andrea/Escritorio/CERN data/Try3/all_1000.root\")\n",
    "intree = rfile.Get(\"Nominal\")\n",
    "array = tree2array(intree)\n",
    "df = pd.DataFrame(array)\n",
    "df = sel_df(df, \"SR_1tag\")\n",
    "\n",
    "# Delete columns\n",
    "not_cons = ['sample', 'EventWeight', 'EventNumber', 'm_region', 'm_FJNbtagJets', 'm_FJphi', 'm_FJeta', 'm_DTeta', 'm_DTphi']\n",
    "df.drop(not_cons, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing data for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 14770\n",
      "Test size: 2563\n",
      "Signal amount: 3553 , 0.28 %\n",
      "Background amount: 9262 , 0.72 %\n"
     ]
    }
   ],
   "source": [
    "# Features\n",
    "feature_cols = df.columns.values[:-1]\n",
    "\n",
    "X = df.loc[:, feature_cols].values\n",
    "# Targets\n",
    "y = df['signal'].values\n",
    "\n",
    "#from imblearn.over_sampling import RandomOverSampler\n",
    "#ros = RandomOverSampler(random_state=0)\n",
    "#X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "#https://imbalanced-learn.readthedocs.io/en/stable/over_sampling.html\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Training size:\",X_train.shape[0])\n",
    "print(\"Test size:\", X_test.shape[0])\n",
    "values, counts = np.unique(y, return_counts=True)\n",
    "print(\"Signal amount:\", counts[1],\",\", round(counts[1]/y.shape[0], 2),\"%\")\n",
    "print(\"Background amount:\", counts[0],\",\", round(counts[0]/y.shape[0], 2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal training events: 7385 , 0.5 %\n",
      "Background training events: 7385 , 0.5 %\n",
      "Signal testing events: 686 , 0.27 %\n",
      "Background testing events: 1877 , 0.73 %\n"
     ]
    }
   ],
   "source": [
    "values_s, count_s = np.unique(y_train, return_counts=True)\n",
    "print(\"Signal training events:\", count_s[1],\",\", round(count_s[1]/X_train.shape[0], 2),\"%\")\n",
    "print(\"Background training events:\", count_s[0],\",\", round(count_s[0]/X_train.shape[0],2),\"%\")\n",
    "values_b, count_b = np.unique(y_test, return_counts=True)\n",
    "print(\"Signal testing events:\", count_b[1],\",\", round(count_b[1]/X_test.shape[0],2),\"%\")\n",
    "print(\"Background testing events:\", count_b[0],\",\", round(count_b[0]/X_test.shape[0],2),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom metric: F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_(y_true, y_pred):\n",
    "    def recall_(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision_(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision_(y_true, y_pred)\n",
    "    recall = recall_(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()\n",
    "#First Hidden Layer\n",
    "classifier.add(Dense(100, activation='relu', kernel_initializer='uniform', input_dim=10))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "#Second  Hidden Layer\n",
    "classifier.add(Dense(100, activation='relu', kernel_initializer='uniform'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "#Third  Hidden Layer\n",
    "classifier.add(Dense(100, activation='relu', kernel_initializer='uniform'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "#Fourth Hidden Layer\n",
    "classifier.add(Dense(100, activation='relu', kernel_initializer='uniform'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "#Fifth Hidden Layer\n",
    "classifier.add(Dense(100, activation='relu', kernel_initializer='uniform'))\n",
    "classifier.add(Dropout(rate= 0.1))\n",
    "#Output Layer\n",
    "classifier.add(Dense(1, activation='sigmoid', kernel_initializer='uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the neural network\n",
    "classifier.compile(optimizer ='adam',loss='binary_crossentropy', metrics =[f1_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14770/14770 [==============================] - 2s 163us/step - loss: 0.6696 - f1_: 0.6498\n",
      "Epoch 2/200\n",
      "14770/14770 [==============================] - 2s 111us/step - loss: 0.6414 - f1_: 0.6826\n",
      "Epoch 3/200\n",
      "14770/14770 [==============================] - 2s 109us/step - loss: 0.6322 - f1_: 0.6846\n",
      "Epoch 4/200\n",
      "14770/14770 [==============================] - 2s 120us/step - loss: 0.5970 - f1_: 0.7059\n",
      "Epoch 5/200\n",
      "14770/14770 [==============================] - 2s 111us/step - loss: 0.5823 - f1_: 0.7182\n",
      "Epoch 6/200\n",
      "14770/14770 [==============================] - 2s 113us/step - loss: 0.5689 - f1_: 0.7250\n",
      "Epoch 7/200\n",
      "14770/14770 [==============================] - 2s 118us/step - loss: 0.5565 - f1_: 0.7306\n",
      "Epoch 8/200\n",
      "14770/14770 [==============================] - 2s 132us/step - loss: 0.5531 - f1_: 0.7381\n",
      "Epoch 9/200\n",
      "14770/14770 [==============================] - 1s 100us/step - loss: 0.5510 - f1_: 0.7376\n",
      "Epoch 10/200\n",
      "14770/14770 [==============================] - 2s 105us/step - loss: 0.5466 - f1_: 0.7396\n",
      "Epoch 11/200\n",
      "14770/14770 [==============================] - 1s 99us/step - loss: 0.5485 - f1_: 0.7374\n",
      "Epoch 12/200\n",
      "14770/14770 [==============================] - 2s 105us/step - loss: 0.5417 - f1_: 0.7453\n",
      "Epoch 13/200\n",
      "14770/14770 [==============================] - 2s 106us/step - loss: 0.5367 - f1_: 0.7534\n",
      "Epoch 14/200\n",
      "14770/14770 [==============================] - 1s 100us/step - loss: 0.5554 - f1_: 0.7342\n",
      "Epoch 15/200\n",
      "14770/14770 [==============================] - 1s 100us/step - loss: 0.5609 - f1_: 0.7297\n",
      "Epoch 16/200\n",
      "14770/14770 [==============================] - 2s 106us/step - loss: 0.5460 - f1_: 0.7453\n",
      "Epoch 17/200\n",
      "14770/14770 [==============================] - 1s 100us/step - loss: 0.5502 - f1_: 0.7305\n",
      "Epoch 18/200\n",
      "14770/14770 [==============================] - 2s 106us/step - loss: 0.5446 - f1_: 0.7477\n",
      "Epoch 19/200\n",
      "14770/14770 [==============================] - 2s 116us/step - loss: 0.5417 - f1_: 0.7493\n",
      "Epoch 20/200\n",
      "14770/14770 [==============================] - 2s 108us/step - loss: 0.5496 - f1_: 0.7437\n",
      "Epoch 21/200\n",
      "14770/14770 [==============================] - 2s 128us/step - loss: 0.5404 - f1_: 0.7508\n",
      "Epoch 22/200\n",
      "14770/14770 [==============================] - 2s 127us/step - loss: 0.5374 - f1_: 0.7506\n",
      "Epoch 23/200\n",
      "14770/14770 [==============================] - 2s 131us/step - loss: 0.5437 - f1_: 0.7482\n",
      "Epoch 24/200\n",
      "14770/14770 [==============================] - 2s 140us/step - loss: 0.5453 - f1_: 0.7443\n",
      "Epoch 25/200\n",
      "14770/14770 [==============================] - 2s 130us/step - loss: 0.5561 - f1_: 0.7340\n",
      "Epoch 26/200\n",
      "14770/14770 [==============================] - 2s 115us/step - loss: 0.5361 - f1_: 0.7526\n",
      "Epoch 27/200\n",
      "14770/14770 [==============================] - 2s 113us/step - loss: 0.5425 - f1_: 0.7488\n",
      "Epoch 28/200\n",
      "14770/14770 [==============================] - 2s 108us/step - loss: 0.5437 - f1_: 0.7427\n",
      "Epoch 29/200\n",
      "14770/14770 [==============================] - 2s 105us/step - loss: 0.5387 - f1_: 0.7503\n",
      "Epoch 30/200\n",
      "14770/14770 [==============================] - 2s 112us/step - loss: 0.5409 - f1_: 0.7544\n",
      "Epoch 31/200\n",
      "14770/14770 [==============================] - 2s 122us/step - loss: 0.5326 - f1_: 0.7560\n",
      "Epoch 32/200\n",
      "14770/14770 [==============================] - 2s 130us/step - loss: 0.5296 - f1_: 0.7620\n",
      "Epoch 33/200\n",
      "14770/14770 [==============================] - 2s 128us/step - loss: 0.5364 - f1_: 0.7496\n",
      "Epoch 34/200\n",
      "14770/14770 [==============================] - 2s 110us/step - loss: 0.5372 - f1_: 0.7515\n",
      "Epoch 35/200\n",
      "14770/14770 [==============================] - 2s 120us/step - loss: 0.5289 - f1_: 0.7597\n",
      "Epoch 36/200\n",
      "14770/14770 [==============================] - 2s 128us/step - loss: 0.5287 - f1_: 0.7614\n",
      "Epoch 37/200\n",
      "14770/14770 [==============================] - 2s 125us/step - loss: 0.5265 - f1_: 0.7630\n",
      "Epoch 38/200\n",
      "14770/14770 [==============================] - 3s 175us/step - loss: 0.5372 - f1_: 0.7538\n",
      "Epoch 39/200\n",
      "14770/14770 [==============================] - 4s 241us/step - loss: 0.5260 - f1_: 0.7619\n",
      "Epoch 40/200\n",
      "14770/14770 [==============================] - 3s 201us/step - loss: 0.5263 - f1_: 0.7623\n",
      "Epoch 41/200\n",
      "14770/14770 [==============================] - 3s 189us/step - loss: 0.5311 - f1_: 0.7582\n",
      "Epoch 42/200\n",
      "14770/14770 [==============================] - 2s 167us/step - loss: 0.5320 - f1_: 0.7618\n",
      "Epoch 43/200\n",
      "14770/14770 [==============================] - 2s 150us/step - loss: 0.5236 - f1_: 0.7667\n",
      "Epoch 44/200\n",
      "14770/14770 [==============================] - 3s 219us/step - loss: 0.5294 - f1_: 0.7611\n",
      "Epoch 45/200\n",
      "14770/14770 [==============================] - 4s 250us/step - loss: 0.5298 - f1_: 0.7538\n",
      "Epoch 46/200\n",
      "14770/14770 [==============================] - 4s 240us/step - loss: 0.5275 - f1_: 0.7578\n",
      "Epoch 47/200\n",
      "14770/14770 [==============================] - 4s 258us/step - loss: 0.5295 - f1_: 0.7616\n",
      "Epoch 48/200\n",
      "14770/14770 [==============================] - 3s 193us/step - loss: 0.5286 - f1_: 0.7619\n",
      "Epoch 49/200\n",
      "14770/14770 [==============================] - 3s 187us/step - loss: 0.5247 - f1_: 0.7631\n",
      "Epoch 50/200\n",
      "14770/14770 [==============================] - 3s 205us/step - loss: 0.5300 - f1_: 0.7603\n",
      "Epoch 51/200\n",
      "14770/14770 [==============================] - 3s 196us/step - loss: 0.5276 - f1_: 0.7668\n",
      "Epoch 52/200\n",
      "14770/14770 [==============================] - 2s 167us/step - loss: 0.5283 - f1_: 0.7617\n",
      "Epoch 53/200\n",
      "14770/14770 [==============================] - 2s 162us/step - loss: 0.5297 - f1_: 0.7627\n",
      "Epoch 54/200\n",
      "14770/14770 [==============================] - 2s 157us/step - loss: 0.5434 - f1_: 0.7479\n",
      "Epoch 55/200\n",
      "14770/14770 [==============================] - 2s 138us/step - loss: 0.5506 - f1_: 0.7313\n",
      "Epoch 56/200\n",
      "14770/14770 [==============================] - 2s 157us/step - loss: 0.5437 - f1_: 0.7400\n",
      "Epoch 57/200\n",
      "14770/14770 [==============================] - 2s 126us/step - loss: 0.5474 - f1_: 0.7344\n",
      "Epoch 58/200\n",
      "14770/14770 [==============================] - 2s 116us/step - loss: 0.5414 - f1_: 0.7472\n",
      "Epoch 59/200\n",
      "14770/14770 [==============================] - 2s 128us/step - loss: 0.5536 - f1_: 0.7422\n",
      "Epoch 60/200\n",
      "14770/14770 [==============================] - 3s 186us/step - loss: 0.5511 - f1_: 0.7372\n",
      "Epoch 61/200\n",
      "14770/14770 [==============================] - 2s 164us/step - loss: 0.5412 - f1_: 0.7488\n",
      "Epoch 62/200\n",
      "14770/14770 [==============================] - 2s 164us/step - loss: 0.5604 - f1_: 0.7281\n",
      "Epoch 63/200\n",
      "14770/14770 [==============================] - 2s 142us/step - loss: 0.5439 - f1_: 0.7433\n",
      "Epoch 64/200\n",
      "14770/14770 [==============================] - 2s 144us/step - loss: 0.5577 - f1_: 0.7492\n",
      "Epoch 65/200\n",
      "14770/14770 [==============================] - 2s 151us/step - loss: 0.5505 - f1_: 0.7511\n",
      "Epoch 66/200\n",
      "14770/14770 [==============================] - 2s 166us/step - loss: 0.5358 - f1_: 0.7629\n",
      "Epoch 67/200\n",
      "14770/14770 [==============================] - 2s 167us/step - loss: 0.5271 - f1_: 0.7616\n",
      "Epoch 68/200\n",
      "14770/14770 [==============================] - 2s 133us/step - loss: 0.5400 - f1_: 0.7525\n",
      "Epoch 69/200\n",
      "14770/14770 [==============================] - 2s 141us/step - loss: 0.5262 - f1_: 0.7663\n",
      "Epoch 70/200\n",
      "14770/14770 [==============================] - 2s 135us/step - loss: 0.5238 - f1_: 0.7652\n",
      "Epoch 71/200\n",
      "14770/14770 [==============================] - 2s 143us/step - loss: 0.5224 - f1_: 0.7685\n",
      "Epoch 72/200\n",
      "14770/14770 [==============================] - 2s 133us/step - loss: 0.5298 - f1_: 0.7617\n",
      "Epoch 73/200\n",
      "14770/14770 [==============================] - 3s 190us/step - loss: 0.5220 - f1_: 0.7689\n",
      "Epoch 74/200\n",
      "14770/14770 [==============================] - 3s 180us/step - loss: 0.5285 - f1_: 0.7657\n",
      "Epoch 75/200\n",
      "14770/14770 [==============================] - 2s 164us/step - loss: 0.5302 - f1_: 0.7600\n",
      "Epoch 76/200\n",
      "14770/14770 [==============================] - 2s 133us/step - loss: 0.5223 - f1_: 0.7681\n",
      "Epoch 77/200\n",
      "14770/14770 [==============================] - 2s 153us/step - loss: 0.5341 - f1_: 0.7542\n",
      "Epoch 78/200\n",
      "14770/14770 [==============================] - 2s 156us/step - loss: 0.5224 - f1_: 0.7630\n",
      "Epoch 79/200\n",
      "14770/14770 [==============================] - 2s 149us/step - loss: 0.5142 - f1_: 0.7699\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14770/14770 [==============================] - 3s 172us/step - loss: 0.5264 - f1_: 0.7635\n",
      "Epoch 81/200\n",
      "14770/14770 [==============================] - 2s 150us/step - loss: 0.5231 - f1_: 0.7643\n",
      "Epoch 82/200\n",
      "14770/14770 [==============================] - 2s 158us/step - loss: 0.5247 - f1_: 0.7658\n",
      "Epoch 83/200\n",
      "14770/14770 [==============================] - 2s 145us/step - loss: 0.5437 - f1_: 0.7554\n",
      "Epoch 84/200\n",
      "14770/14770 [==============================] - 2s 136us/step - loss: 0.5240 - f1_: 0.7657\n",
      "Epoch 85/200\n",
      "14770/14770 [==============================] - 2s 133us/step - loss: 0.5219 - f1_: 0.7667\n",
      "Epoch 86/200\n",
      "14770/14770 [==============================] - 3s 174us/step - loss: 0.5263 - f1_: 0.7654\n",
      "Epoch 87/200\n",
      "14770/14770 [==============================] - 3s 174us/step - loss: 0.5221 - f1_: 0.7683\n",
      "Epoch 88/200\n",
      "14770/14770 [==============================] - 2s 133us/step - loss: 0.5220 - f1_: 0.7681\n",
      "Epoch 89/200\n",
      "14770/14770 [==============================] - 2s 143us/step - loss: 0.5261 - f1_: 0.7593\n",
      "Epoch 90/200\n",
      "14770/14770 [==============================] - 2s 153us/step - loss: 0.5367 - f1_: 0.7638\n",
      "Epoch 91/200\n",
      "14770/14770 [==============================] - 2s 130us/step - loss: 0.5237 - f1_: 0.7638\n",
      "Epoch 92/200\n",
      "14770/14770 [==============================] - 2s 116us/step - loss: 0.5232 - f1_: 0.7671\n",
      "Epoch 93/200\n",
      "14770/14770 [==============================] - 2s 126us/step - loss: 0.5290 - f1_: 0.7594\n",
      "Epoch 94/200\n",
      "14770/14770 [==============================] - 3s 182us/step - loss: 0.5440 - f1_: 0.7452\n",
      "Epoch 95/200\n",
      "14770/14770 [==============================] - 2s 153us/step - loss: 0.5991 - f1_: 0.6788\n",
      "Epoch 96/200\n",
      "14770/14770 [==============================] - 2s 123us/step - loss: 0.5969 - f1_: 0.6835\n",
      "Epoch 97/200\n",
      "14770/14770 [==============================] - 2s 121us/step - loss: 0.5489 - f1_: 0.7474\n",
      "Epoch 98/200\n",
      "14770/14770 [==============================] - 2s 131us/step - loss: 0.5435 - f1_: 0.7430\n",
      "Epoch 99/200\n",
      "14770/14770 [==============================] - 2s 131us/step - loss: 0.5282 - f1_: 0.7625\n",
      "Epoch 100/200\n",
      "14770/14770 [==============================] - 2s 137us/step - loss: 0.5376 - f1_: 0.7509\n",
      "Epoch 101/200\n",
      "14770/14770 [==============================] - 2s 131us/step - loss: 0.5370 - f1_: 0.7537\n",
      "Epoch 102/200\n",
      "14770/14770 [==============================] - 2s 123us/step - loss: 0.5367 - f1_: 0.7569\n",
      "Epoch 103/200\n",
      "14770/14770 [==============================] - 2s 114us/step - loss: 0.5402 - f1_: 0.7530\n",
      "Epoch 104/200\n",
      "14770/14770 [==============================] - 2s 135us/step - loss: 0.5276 - f1_: 0.7631\n",
      "Epoch 105/200\n",
      "14770/14770 [==============================] - 2s 136us/step - loss: 0.5222 - f1_: 0.7575\n",
      "Epoch 106/200\n",
      "14770/14770 [==============================] - 2s 125us/step - loss: 0.5262 - f1_: 0.7533\n",
      "Epoch 107/200\n",
      "14770/14770 [==============================] - 2s 124us/step - loss: 0.5312 - f1_: 0.7514\n",
      "Epoch 108/200\n",
      "14770/14770 [==============================] - 2s 122us/step - loss: 0.5177 - f1_: 0.7564\n",
      "Epoch 109/200\n",
      "14770/14770 [==============================] - 2s 131us/step - loss: 0.5313 - f1_: 0.7359\n",
      "Epoch 110/200\n",
      "14770/14770 [==============================] - 2s 159us/step - loss: 0.5341 - f1_: 0.7394\n",
      "Epoch 111/200\n",
      "14770/14770 [==============================] - 4s 286us/step - loss: 0.5224 - f1_: 0.7475\n",
      "Epoch 112/200\n",
      "14770/14770 [==============================] - 3s 178us/step - loss: 0.5351 - f1_: 0.7319\n",
      "Epoch 113/200\n",
      "14770/14770 [==============================] - 3s 176us/step - loss: 0.5172 - f1_: 0.7581\n",
      "Epoch 114/200\n",
      "14770/14770 [==============================] - 3s 178us/step - loss: 0.5231 - f1_: 0.7609\n",
      "Epoch 115/200\n",
      "14770/14770 [==============================] - 2s 148us/step - loss: 0.5172 - f1_: 0.7579\n",
      "Epoch 116/200\n",
      "14770/14770 [==============================] - 3s 224us/step - loss: 0.5246 - f1_: 0.7489\n",
      "Epoch 117/200\n",
      "14770/14770 [==============================] - 3s 218us/step - loss: 0.5166 - f1_: 0.7591\n",
      "Epoch 118/200\n",
      "14770/14770 [==============================] - 5s 336us/step - loss: 0.5157 - f1_: 0.7548\n",
      "Epoch 119/200\n",
      "14770/14770 [==============================] - 3s 229us/step - loss: 0.5139 - f1_: 0.7579\n",
      "Epoch 120/200\n",
      "14770/14770 [==============================] - 3s 178us/step - loss: 0.5177 - f1_: 0.7492\n",
      "Epoch 121/200\n",
      "14770/14770 [==============================] - 3s 188us/step - loss: 0.5167 - f1_: 0.7472\n",
      "Epoch 122/200\n",
      "14770/14770 [==============================] - 4s 242us/step - loss: 0.5215 - f1_: 0.7553\n",
      "Epoch 123/200\n",
      "14770/14770 [==============================] - 3s 181us/step - loss: 0.5451 - f1_: 0.7576\n",
      "Epoch 124/200\n",
      "14770/14770 [==============================] - 3s 209us/step - loss: 0.5109 - f1_: 0.7609\n",
      "Epoch 125/200\n",
      "14770/14770 [==============================] - 3s 210us/step - loss: 0.5194 - f1_: 0.7516\n",
      "Epoch 126/200\n",
      "14770/14770 [==============================] - 3s 176us/step - loss: 0.5213 - f1_: 0.7444\n",
      "Epoch 127/200\n",
      "14770/14770 [==============================] - 3s 236us/step - loss: 0.5132 - f1_: 0.7532\n",
      "Epoch 128/200\n",
      "14770/14770 [==============================] - 3s 197us/step - loss: 0.5211 - f1_: 0.7529\n",
      "Epoch 129/200\n",
      "14770/14770 [==============================] - 3s 198us/step - loss: 0.5234 - f1_: 0.7477\n",
      "Epoch 130/200\n",
      "14770/14770 [==============================] - 4s 244us/step - loss: 0.5185 - f1_: 0.7487\n",
      "Epoch 131/200\n",
      "14770/14770 [==============================] - 3s 194us/step - loss: 0.5200 - f1_: 0.7424\n",
      "Epoch 132/200\n",
      "14770/14770 [==============================] - 4s 248us/step - loss: 0.5201 - f1_: 0.7552\n",
      "Epoch 133/200\n",
      "14770/14770 [==============================] - 3s 219us/step - loss: 0.5190 - f1_: 0.7498\n",
      "Epoch 134/200\n",
      "14770/14770 [==============================] - 4s 252us/step - loss: 0.5162 - f1_: 0.7455\n",
      "Epoch 135/200\n",
      "14770/14770 [==============================] - 5s 308us/step - loss: 0.5132 - f1_: 0.7582\n",
      "Epoch 136/200\n",
      "14770/14770 [==============================] - 2s 152us/step - loss: 0.5141 - f1_: 0.7488\n",
      "Epoch 137/200\n",
      "14770/14770 [==============================] - 2s 142us/step - loss: 0.5172 - f1_: 0.7525\n",
      "Epoch 138/200\n",
      "14770/14770 [==============================] - 2s 134us/step - loss: 0.5189 - f1_: 0.7462\n",
      "Epoch 139/200\n",
      "14770/14770 [==============================] - 2s 116us/step - loss: 0.5169 - f1_: 0.7511\n",
      "Epoch 140/200\n",
      "14770/14770 [==============================] - 2s 140us/step - loss: 0.5141 - f1_: 0.7520\n",
      "Epoch 141/200\n",
      "14770/14770 [==============================] - 2s 156us/step - loss: 0.5192 - f1_: 0.7515\n",
      "Epoch 142/200\n",
      "14770/14770 [==============================] - 2s 144us/step - loss: 0.5187 - f1_: 0.7610\n",
      "Epoch 143/200\n",
      "14770/14770 [==============================] - 2s 145us/step - loss: 0.5173 - f1_: 0.7479\n",
      "Epoch 144/200\n",
      "14770/14770 [==============================] - 2s 131us/step - loss: 0.5810 - f1_: 0.7183\n",
      "Epoch 145/200\n",
      "14770/14770 [==============================] - 2s 136us/step - loss: 0.6011 - f1_: 0.7167\n",
      "Epoch 146/200\n",
      "14770/14770 [==============================] - 2s 128us/step - loss: 0.5695 - f1_: 0.7309\n",
      "Epoch 147/200\n",
      "14770/14770 [==============================] - 2s 122us/step - loss: 0.5272 - f1_: 0.7546\n",
      "Epoch 148/200\n",
      "14770/14770 [==============================] - 2s 128us/step - loss: 0.5146 - f1_: 0.7563\n",
      "Epoch 149/200\n",
      "14770/14770 [==============================] - 2s 143us/step - loss: 0.5268 - f1_: 0.7401\n",
      "Epoch 150/200\n",
      "14770/14770 [==============================] - 2s 143us/step - loss: 0.5304 - f1_: 0.7513\n",
      "Epoch 151/200\n",
      "14770/14770 [==============================] - 2s 129us/step - loss: 0.5244 - f1_: 0.7616\n",
      "Epoch 152/200\n",
      "14770/14770 [==============================] - 2s 123us/step - loss: 0.5241 - f1_: 0.7582\n",
      "Epoch 153/200\n",
      "14770/14770 [==============================] - 2s 141us/step - loss: 0.5148 - f1_: 0.7561\n",
      "Epoch 154/200\n",
      "14770/14770 [==============================] - 2s 138us/step - loss: 0.5149 - f1_: 0.7597\n",
      "Epoch 155/200\n",
      "14770/14770 [==============================] - 2s 147us/step - loss: 0.5798 - f1_: 0.7324\n",
      "Epoch 156/200\n",
      "14770/14770 [==============================] - 2s 130us/step - loss: 0.5837 - f1_: 0.7244\n",
      "Epoch 157/200\n",
      "14770/14770 [==============================] - 2s 129us/step - loss: 0.5713 - f1_: 0.7270\n",
      "Epoch 158/200\n",
      "14770/14770 [==============================] - 2s 154us/step - loss: 0.5214 - f1_: 0.7490\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14770/14770 [==============================] - 3s 182us/step - loss: 0.5224 - f1_: 0.7501\n",
      "Epoch 160/200\n",
      "14770/14770 [==============================] - 2s 166us/step - loss: 0.5221 - f1_: 0.7475\n",
      "Epoch 161/200\n",
      "14770/14770 [==============================] - 4s 243us/step - loss: 0.5191 - f1_: 0.7448\n",
      "Epoch 162/200\n",
      "14770/14770 [==============================] - 3s 180us/step - loss: 0.5085 - f1_: 0.7508\n",
      "Epoch 163/200\n",
      "14770/14770 [==============================] - 3s 174us/step - loss: 0.5717 - f1_: 0.7270\n",
      "Epoch 164/200\n",
      "14770/14770 [==============================] - 3s 232us/step - loss: 0.5592 - f1_: 0.7477\n",
      "Epoch 165/200\n",
      "14770/14770 [==============================] - 4s 278us/step - loss: 0.5506 - f1_: 0.7591\n",
      "Epoch 166/200\n",
      "14770/14770 [==============================] - 3s 200us/step - loss: 0.5313 - f1_: 0.7559\n",
      "Epoch 167/200\n",
      "14770/14770 [==============================] - 3s 230us/step - loss: 0.5395 - f1_: 0.7463\n",
      "Epoch 168/200\n",
      "14770/14770 [==============================] - 3s 195us/step - loss: 0.5209 - f1_: 0.7649\n",
      "Epoch 169/200\n",
      "14770/14770 [==============================] - 4s 247us/step - loss: 0.5121 - f1_: 0.7595\n",
      "Epoch 170/200\n",
      "14770/14770 [==============================] - 4s 283us/step - loss: 0.5156 - f1_: 0.7544\n",
      "Epoch 171/200\n",
      "14770/14770 [==============================] - 5s 337us/step - loss: 0.5134 - f1_: 0.7586\n",
      "Epoch 172/200\n",
      "14770/14770 [==============================] - 5s 317us/step - loss: 0.5237 - f1_: 0.7431\n",
      "Epoch 173/200\n",
      "14770/14770 [==============================] - ETA: 0s - loss: 0.5239 - f1_: 0.750 - 3s 225us/step - loss: 0.5240 - f1_: 0.7502\n",
      "Epoch 174/200\n",
      "14770/14770 [==============================] - 3s 206us/step - loss: 0.5317 - f1_: 0.7451\n",
      "Epoch 175/200\n",
      "14770/14770 [==============================] - 2s 162us/step - loss: 0.5256 - f1_: 0.7516\n",
      "Epoch 176/200\n",
      "14770/14770 [==============================] - 2s 169us/step - loss: 0.5188 - f1_: 0.7539\n",
      "Epoch 177/200\n",
      "14770/14770 [==============================] - 3s 223us/step - loss: 0.5857 - f1_: 0.7292\n",
      "Epoch 178/200\n",
      "14770/14770 [==============================] - 2s 165us/step - loss: 0.5861 - f1_: 0.7222\n",
      "Epoch 179/200\n",
      "14770/14770 [==============================] - 4s 247us/step - loss: 0.6058 - f1_: 0.7227\n",
      "Epoch 180/200\n",
      "14770/14770 [==============================] - 3s 228us/step - loss: 0.5761 - f1_: 0.7092\n",
      "Epoch 181/200\n",
      "14770/14770 [==============================] - 2s 141us/step - loss: 0.5265 - f1_: 0.7603\n",
      "Epoch 182/200\n",
      "14770/14770 [==============================] - 3s 188us/step - loss: 0.5171 - f1_: 0.7494\n",
      "Epoch 183/200\n",
      "14770/14770 [==============================] - 3s 193us/step - loss: 0.5119 - f1_: 0.7525\n",
      "Epoch 184/200\n",
      "14770/14770 [==============================] - 2s 155us/step - loss: 0.5711 - f1_: 0.7389\n",
      "Epoch 185/200\n",
      "14770/14770 [==============================] - 3s 172us/step - loss: 0.6408 - f1_: 0.6899\n",
      "Epoch 186/200\n",
      "14770/14770 [==============================] - 3s 178us/step - loss: 0.5794 - f1_: 0.7138\n",
      "Epoch 187/200\n",
      "14770/14770 [==============================] - 3s 188us/step - loss: 0.6541 - f1_: 0.4659\n",
      "Epoch 188/200\n",
      "14770/14770 [==============================] - 2s 138us/step - loss: 0.5261 - f1_: 0.7634\n",
      "Epoch 189/200\n",
      "14770/14770 [==============================] - 2s 139us/step - loss: 0.5184 - f1_: 0.7587\n",
      "Epoch 190/200\n",
      "14770/14770 [==============================] - 2s 133us/step - loss: 0.5098 - f1_: 0.7663\n",
      "Epoch 191/200\n",
      "14770/14770 [==============================] - 2s 129us/step - loss: 0.5323 - f1_: 0.7487\n",
      "Epoch 192/200\n",
      "14770/14770 [==============================] - 2s 148us/step - loss: 0.5201 - f1_: 0.7620\n",
      "Epoch 193/200\n",
      "14770/14770 [==============================] - 2s 167us/step - loss: 0.5279 - f1_: 0.7482\n",
      "Epoch 194/200\n",
      "14770/14770 [==============================] - 5s 319us/step - loss: 0.5214 - f1_: 0.7579\n",
      "Epoch 195/200\n",
      "14770/14770 [==============================] - 3s 187us/step - loss: 0.5203 - f1_: 0.7519\n",
      "Epoch 196/200\n",
      "14770/14770 [==============================] - 2s 151us/step - loss: 0.5112 - f1_: 0.7606\n",
      "Epoch 197/200\n",
      "14770/14770 [==============================] - 2s 164us/step - loss: 0.5287 - f1_: 0.7391\n",
      "Epoch 198/200\n",
      "14770/14770 [==============================] - 4s 276us/step - loss: 0.5162 - f1_: 0.7628\n",
      "Epoch 199/200\n",
      "14770/14770 [==============================] - 3s 169us/step - loss: 0.5108 - f1_: 0.7512\n",
      "Epoch 200/200\n",
      "14770/14770 [==============================] - 2s 162us/step - loss: 0.5085 - f1_: 0.7553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8e9dca1860>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the data to the training dataset\n",
    "classifier.fit(X_train,y_train, batch_size=50, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.846127978552712"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_prob = classifier.predict(X_test)\n",
    "y_pred = (y_pred_prob>0.5)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob, pos_label=1)\n",
    "plt.plot(fpr, tpr)\n",
    "roc_auc_score(y_test, y_pred_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.922740524781341\n",
      "precision: 0.4282814614343708\n",
      "accuracy: 0.649629340616465\n"
     ]
    }
   ],
   "source": [
    "r = recall_score(y_test,y_pred)\n",
    "p = precision_score(y_test,y_pred)\n",
    "a = accuracy_score(y_test,y_pred)\n",
    "\n",
    "print(\"recall:\", r)\n",
    "print(\"precision:\", p)\n",
    "print(\"accuracy:\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8ea1d81518>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "plt.plot(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1032  845]\n",
      " [  53  633]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:20]\n",
    "aux = np.concatenate(y_pred[:20])\n",
    "1*aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO:\n",
    "\n",
    "- Ver mtodo de oversampling debido al desbalanceo de los datos. Un mtodo tpico es el SMOTE.\n",
    "- Hacer una tabla resumen de las configuraciones de regin y seal, para generar los modelos de entrenamiento, contar la cantidad de seal y background en cada configuracin.\n",
    "- Usar f1 de HER2 como mtrica de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
