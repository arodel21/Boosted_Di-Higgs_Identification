{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>TMVA Classification Using Deep Neural Networks</center>\n",
    "\n",
    "In this notebook we still classify di-Higgs new data with Deep Neural Networks meethod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT\n",
    "from ROOT import TMVA, TTree\n",
    "import pandas as pd\n",
    "\n",
    "ROOT.TMVA.Tools.Instance()\n",
    "## For PYMVA methods\n",
    "TMVA.PyMethodBase.PyInitialize()\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, SGD\n",
    "#from keras.initializers import TruncatedNormal\n",
    "#from keras import initializations\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Reshape\n",
    "#from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import itertools\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "from array import array\n",
    "import numpy as np\n",
    "\n",
    "from root_numpy import root2array, tree2array\n",
    "\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter dataset by region.\n",
    "\n",
    "This function will let you filter your dataset by region. It's known that SR_1tag is very signal poor, while SR_2tag has a lot a signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_region(file, region, signal):\n",
    "    oldfile = ROOT.TFile(file)\n",
    "    oldtree = oldfile.Nominal\n",
    "    signal_file = ROOT.TFile(region+\"_\"+signal+\"_s.root\",\"recreate\")\n",
    "    signal_tree = oldtree.CloneTree(0)\n",
    "    backg_file = ROOT.TFile(region+\"_\"+signal+\"_b.root\",\"recreate\")\n",
    "    backg_tree = oldtree.CloneTree(0)\n",
    "    data_file = ROOT.TFile(region+\"_\"+signal+\"_d.root\",\"recreate\")\n",
    "    data_tree = oldtree.CloneTree(0)\n",
    "    for entry in oldtree:\n",
    "        if (entry.m_region == region):\n",
    "            if (entry.sample == \"data\"):\n",
    "                data_tree.Fill()\n",
    "            elif (entry.sample == \"Xtohh1000\"): #signal\n",
    "                signal_tree.Fill()\n",
    "            else:\n",
    "                backg_tree.Fill()\n",
    "    signal_tree.AutoSave()   \n",
    "    backg_tree.AutoSave()\n",
    "    data_tree.AutoSave()\n",
    "    return signal_tree, signal_file, backg_tree, backg_file, data_tree, data_file\n",
    "\n",
    "#Use as\n",
    "#tree, file = filter_region(\"data.root\", \"SR_1tag\", \"small.root\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Factory and Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.root has unlabeled data points (called data) and fakes points. For the background training we'll use only the fakes points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_tree, signal_file, backg_tree, backg_file, data_tree, data_file = filter_region(\"all_1000.root\", \"SR_1tag\", \"Xtohh1000\")\n",
    "\n",
    "outputFile = ROOT.TFile.Open(\"Higgs_ClassificationOutput.root\", \"RECREATE\")\n",
    "\n",
    "# Factory\n",
    "factory = ROOT.TMVA.Factory(\"TMVA_Higgs_Classification\", outputFile,\n",
    "                      \"!V:ROC:!Silent:Color:!DrawProgressBar:AnalysisType=Classification\" )\n",
    "\n",
    "#signal_tree.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare DataLoader(s)\n",
    "\n",
    "The next step is to declare the DataLoader class that deals with input data abd variables \n",
    "\n",
    "We add first the signal and background trees in the data loader and then we\n",
    "define the input variables that shall be used for the MVA training\n",
    "note that you may also use variable expressions, which can be parsed by TTree::Draw( \"expression\" )]\n",
    "\n",
    "We have two kinds of signals and for the training we have to use only one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSetInfo              : [dataset] : Added class \"Signal\"\n",
      "                         : Add Tree Nominal of type Signal with 3553 events\n",
      "DataSetInfo              : [dataset] : Added class \"Background\"\n",
      "                         : Add Tree Nominal of type Background with 9262 events\n"
     ]
    }
   ],
   "source": [
    "loader = ROOT.TMVA.DataLoader(\"dataset\")\n",
    "\n",
    "### global event weights per tree (see below for setting event-wise weights)\n",
    "#signalWeight     = 1.0\n",
    "#backgroundWeight = 1.0\n",
    "   \n",
    "### You can add an arbitrary number of signal or background trees\n",
    "loader.AddSignalTree    ( signal_tree )\n",
    "loader.AddBackgroundTree( backg_tree )\n",
    "loader.SetWeightExpression(\"EventWeight\")\n",
    "\n",
    "not_cons = ['sample', 'EventWeight', 'EventNumber', 'm_region', 'm_FJNbtagJets', 'm_FJphi', 'm_FJeta', 'm_DTeta', 'm_DTphi']\n",
    "\n",
    "## Define input variables \n",
    "for branch in backg_tree.GetListOfBranches():\n",
    "    if branch.GetName() in not_cons:\n",
    "        continue\n",
    "    loader.AddVariable(branch.GetName())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dataset(s)\n",
    "\n",
    "Setup the DataLoader by splitting events in training and test samples. \n",
    "Here we use a random split and a fixed number of training and test events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply additional cuts on the signal and background samples (can be different)\n",
    "mycuts = ROOT.TCut(\"\")   ## for example: TCut mycuts = \"abs(var1)<0.5 && abs(var2-0.5)<1\";\n",
    "mycutb = ROOT.TCut(\"\")   ## for example: TCut mycutb = \"abs(var1)<0.5\";\n",
    "\n",
    "loader.PrepareTrainingAndTestTree(mycuts, mycutb,\n",
    "                                  \"nTrain_Signal=2000:nTrain_Background=2000:SplitMode=Random:\"\n",
    "                                   \"NormMode=NumEvents:!V\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, SGD\n",
    "#from keras.initializers import TruncatedNormal\n",
    "#from keras import initializations\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Reshape\n",
    "#from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 200)               2200      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 402       \n",
      "=================================================================\n",
      "Total params: 83,002\n",
      "Trainable params: 83,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Dense(200, kernel_initializer='he_normal', activation='sigmoid', input_dim=10))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(200, kernel_initializer='he_normal', activation='softsign'))\n",
    "#model.add(Dropout(0.2))\n",
    "#model.add(Dense(64, kernel_initializer='glorot_normal', activation='relu'))\n",
    "model.add(Dense(2, kernel_initializer='he_normal', activation='softmax'))\n",
    "\n",
    "# Set loss and optimizer\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['binary_accuracy'])\n",
    "\n",
    "# Store model to file\n",
    "model.save('model_dense.h5')\n",
    "\n",
    "# Print summary of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ROOT.TMVA::MethodPyKeras object (\"Keras_Dense\") at 0xa1b6d80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mKeras_Dense\u001b[0m\n",
      "                         : \n",
      "Keras_Dense              : [dataset] : Create Transformation \"N\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'm_FJpt' <---> Output : variable 'm_FJpt'\n",
      "                         : Input : variable 'm_FJm' <---> Output : variable 'm_FJm'\n",
      "                         : Input : variable 'm_DTpt' <---> Output : variable 'm_DTpt'\n",
      "                         : Input : variable 'm_DTm' <---> Output : variable 'm_DTm'\n",
      "                         : Input : variable 'm_dPhiFTwDT' <---> Output : variable 'm_dPhiFTwDT'\n",
      "                         : Input : variable 'm_dRFJwDT' <---> Output : variable 'm_dRFJwDT'\n",
      "                         : Input : variable 'm_dPhiDTwMET' <---> Output : variable 'm_dPhiDTwMET'\n",
      "                         : Input : variable 'm_MET' <---> Output : variable 'm_MET'\n",
      "                         : Input : variable 'm_hhm' <---> Output : variable 'm_hhm'\n",
      "                         : Input : variable 'm_bbttpt' <---> Output : variable 'm_bbttpt'\n",
      "                         : Load model from file: model_dense.h5\n"
     ]
    }
   ],
   "source": [
    "factory.BookMethod(loader, ROOT.TMVA.Types.kPyKeras, 'Keras_Dense',\n",
    "        'H:!V:VarTransform=N_AllClasses:FilenameModel=model_dense.h5:'+\\\n",
    "        'NumEpochs=200:BatchSize=32:TriesEarlyStopping=10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factory.TrainAllMethods()\n",
    "\n",
    "# Here we test all methods using the test data set\n",
    "factory.TestAllMethods()\n",
    "\n",
    "# Here we evaluate all methods and compare their performances, computing efficiencies, \n",
    "# ROC curves etc.. using both training and tetsing data sets. Several histograms are \n",
    "# produced which can be examined with the TMVAGui or directly using the output file\n",
    "factory.EvaluateAllMethods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imethod = factory.GetMethod(\"dataset\", \"Keras_Dense\")\n",
    "#TMVA::MethodBase * method = dynamic_cast<MethodBase *>(imethod);\n",
    "icut = method.GetSignalReferenceCut()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC Curve\n",
    "We enable JavaScript visualisation for the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c1 = factory.GetROCCurve(loader)\n",
    "c1.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN Complete Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(file):\n",
    "    params = []\n",
    "    first = 1\n",
    "    with open(file, 'r') as fp:\n",
    "        line = fp.readline().rstrip()\n",
    "        while line:\n",
    "            if (file.split('.')[1] == 'csv' and first):\n",
    "                first = 0\n",
    "                line = fp.readline().rstrip()\n",
    "                continue\n",
    "            params.append(line)\n",
    "            line = fp.readline().rstrip()       \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DNN(params, training, model_input, comp_params, model_name, config, comb):\n",
    "    \n",
    "    output_file = config+ \"_\" + comb + \"_DNN_Classification.root\"\n",
    "    signal_file = config+\"_s.root\"\n",
    "    backg_file = config+\"_b.root\"\n",
    "    \n",
    "    signal_input = ROOT.TFile(signal_file)\n",
    "    signal_tree = signal_input.Nominal\n",
    "    \n",
    "    backg_input = ROOT.TFile(backg_file)\n",
    "    backg_tree = backg_input.Nominal\n",
    "    \n",
    "    outputFile = ROOT.TFile.Open(output_file, \"RECREATE\")\n",
    "\n",
    "    # Factory\n",
    "    factory = ROOT.TMVA.Factory(\"TMVA_Higgs_Classification_\"+config+\"_\"+comb, outputFile,\n",
    "                          \"!V:ROC:Silent:Color:!DrawProgressBar:AnalysisType=Classification\" )\n",
    "\n",
    "    loader = ROOT.TMVA.DataLoader(\"dataset\")\n",
    "\n",
    "    ### global event weights per tree (see below for setting event-wise weights)\n",
    "    #signalWeight     = 1.0\n",
    "    #backgroundWeight = 1.0\n",
    "\n",
    "    ### You can add an arbitrary number of signal or background trees\n",
    "    loader.AddSignalTree    ( signal_tree )\n",
    "    loader.AddBackgroundTree( backg_tree )\n",
    "    loader.SetWeightExpression(\"EventWeight\")\n",
    "    \n",
    "    not_cons = ['sample', 'EventWeight', 'EventNumber', 'm_region', 'm_FJNbtagJets', 'm_FJphi', 'm_FJeta', 'm_DTeta', 'm_DTphi']\n",
    "\n",
    "    ## Define input variables \n",
    "    for branch in backg_tree.GetListOfBranches():\n",
    "        if branch.GetName() in not_cons:\n",
    "            continue\n",
    "        loader.AddVariable(branch.GetName())\n",
    "        \n",
    "    mycuts = ROOT.TCut(\"\")   ## for example: TCut mycuts = \"abs(var1)<0.5 && abs(var2-0.5)<1\";\n",
    "    mycutb = ROOT.TCut(\"\")   ## for example: TCut mycutb = \"abs(var1)<0.5\";\n",
    "\n",
    "\n",
    "    loader.PrepareTrainingAndTestTree(mycuts, mycutb, training)\n",
    "    \n",
    "    # Model structure\n",
    "    \n",
    "    comp_params = comp_params.rstrip()\n",
    "    comp_params = comp_params.split(',')\n",
    "    loss = comp_params[0]\n",
    "    \n",
    "    comp_params.remove(loss)\n",
    "    metrics = comp_params\n",
    "    \n",
    "    model = Sequential()\n",
    "    model_input = model_input.rstrip()\n",
    "    model_input = model_input.split(',')\n",
    "    \n",
    "    hidden_l = int(model_input[0])\n",
    "    neurons = int(model_input[1])\n",
    "    neurons_LF = int(model_input[2])\n",
    "    k_init = model_input[3]\n",
    "    activation_IL = model_input[4]\n",
    "    activation_HL = model_input[5]\n",
    "    activation_FL = model_input[6]\n",
    "    \n",
    "    print(type(neurons))\n",
    "    \n",
    "    model.add(Dense(neurons, kernel_initializer=k_init, activation=activation_IL, input_dim=10))\n",
    "    for h in range(hidden_l):\n",
    "        model.add(Dense(neurons, kernel_initializer=k_init, activation=activation_HL))\n",
    "        \n",
    "    model.add(Dense(neurons_LF, kernel_initializer=k_init, activation=activation_FL))\n",
    "    \n",
    "    # Set loss and optimizer\n",
    "    model.compile(loss=loss, optimizer=Adam(), metrics=metrics)\n",
    "    # Store model to file\n",
    "    model.save(model_name)\n",
    "    # Print summary of model\n",
    "    model.summary()\n",
    "    \n",
    "    ## DNN method\n",
    "    factory.BookMethod(loader,ROOT.TMVA.Types.kPyKeras, \"Keras_Dense\", params)\n",
    "        \n",
    "    factory.TrainAllMethods()\n",
    "    \n",
    "    factory.TestAllMethods()\n",
    "    \n",
    "    factory.EvaluateAllMethods()\n",
    "    \n",
    "    c1 = factory.GetROCCurve(loader)\n",
    "    #c1.Draw()\n",
    "    \n",
    "    integ = factory.GetROCIntegral(loader, \"Keras_Dense\")\n",
    "    \n",
    "    imethod = factory.GetMethod(\"dataset\", \"Keras_Dense\")\n",
    "    #method = dynamic_cast<MethodBase *>(imethod);\n",
    "    icut = imethod.GetSignalReferenceCut()\n",
    "    print(\"cut:\", icut)\n",
    "    \n",
    "    print(\"ROC integral:\", integ)\n",
    "    \n",
    "    outputFile.Close()\n",
    "    signal_input.Close()\n",
    "    backg_input.Close()\n",
    "    \n",
    "    return integ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_combs_params(file_params, file_training, file_model, comp_params, model_name, arr_NumEpochs, arr_BatchSize, arr_nTrain_Signal, arr_nTrain_Background, arr_number_HL, arr_neurons, arr_neurons_LF, arr_k_init, arr_activation_IL, arr_activation_HL, arr_activation_FL, arr_loss, arr_metrics):\n",
    "    comb_params = list(itertools.product(arr_NumEpochs, arr_BatchSize, arr_nTrain_Signal, arr_nTrain_Background, arr_number_HL, arr_neurons, arr_neurons_LF, arr_k_init, arr_activation_IL, arr_activation_HL, arr_activation_FL, arr_loss, arr_metrics))\n",
    "    with open(file_params, 'w') as params, open(file_training, 'w') as training, open(file_model, 'w') as model, open(comp_params, 'w') as comp_p:\n",
    "        model.write(\"number_HL,neurons,neurons_LF,k_init,activation_IL,activation_HL,activation_FL\\n\")\n",
    "        for cp in comb_params:\n",
    "            string1 = \"H:!V:VarTransform=N_AllClasses:FilenameModel=\"+model_name+\":NumEpochs=\"+str(cp[0])+\":BatchSize=\"+str(cp[1])+\":TriesEarlyStopping=10\\n\"\n",
    "            params.write(string1)\n",
    "            string2 = \"nTrain_Signal=\"+str(cp[2])+\"%:nTrain_Background=\"+str(cp[3])+\"%:SplitMode=Random:NormMode=NumEvents:!V\\n\"\n",
    "            training.write(string2)\n",
    "            string3 = str(cp[4])+','+str(cp[5])+','+str(cp[6])+','+str(cp[7])+','+str(cp[8])+','+str(cp[9])+','+str(cp[10])+'\\n'\n",
    "            model.write(string3)\n",
    "            string4 = str(cp[11])+','+str(cp[12])+'\\n'\n",
    "            comp_p.write(string4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_params=\"dnn_params2.txt\"\n",
    "file_training=\"dnn_training2.txt\"\n",
    "file_model=\"dnn_model2.csv\"\n",
    "file_comp_params='comp_params.txt'\n",
    "model_name=\"model_dense.h5\"\n",
    "arr_NumEpochs=[100]\n",
    "arr_BatchSize=[64]\n",
    "arr_nTrain_Signal=[80]\n",
    "arr_nTrain_Background=[80]\n",
    "arr_number_HL=[3]\n",
    "arr_neurons=[100]\n",
    "arr_neurons_LF=[2]\n",
    "arr_k_init=['he_uniform']\n",
    "arr_activation_IL=['relu']\n",
    "arr_activation_HL=['selu']\n",
    "arr_activation_FL=['softmax']\n",
    "arr_loss=['poisson']\n",
    "arr_metrics=['binary_crossentropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_combs_params(file_params, file_training, file_model, file_comp_params, model_name, arr_NumEpochs, arr_BatchSize, arr_nTrain_Signal, arr_nTrain_Background, arr_number_HL, arr_neurons, arr_neurons_LF, arr_k_init, arr_activation_IL, arr_activation_HL, arr_activation_FL, arr_loss, arr_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_opt(config, params, training, model, comp_params, model_name):\n",
    "    max_roc = 0\n",
    "    best_params = \"\"\n",
    "    best_train = \"\"\n",
    "    best_model = \"\"\n",
    "    print(config)\n",
    "    print(\"===============\")\n",
    "    for i in range(len(params)):\n",
    "        roc = DNN(params[i], training[i], model[i], comp_params[i], model_name, config)\n",
    "        print(\"i:\",i)\n",
    "        print(\"ROC:\", roc)\n",
    "        if roc > max_roc:\n",
    "            max_roc = roc\n",
    "            best_params = params[i]\n",
    "            best_train = training[i]\n",
    "            best_model = model[i]\n",
    "            best_comp = comp_params[i]\n",
    "    best_model = best_model.split(',')\n",
    "    best_model_str = \"numero_HL=\"+str(best_model[0])+\", neurons=\"+str(best_model[1])+\", neurons_LF=\"+str(best_model[2])+\", k_init=\"+str(best_model[3])+\", activation_IL=\"+str(best_model[4])+\", activation_HL=\"+str(best_model[5])+\", activation_FL=\"+str(best_model[6])\n",
    "    best_comp = best_comp.split(',')\n",
    "    best_comp_str = \"loss=\"+best_comp[0]+\", metrics=\"+best_comp[1]\n",
    "    print(\"best parameters:\", best_params)\n",
    "    print(\"best training:\", best_train)\n",
    "    print(\"best model:\", best_model_str)\n",
    "    print(\"best comps:\", best_comp_str)\n",
    "    print(\"ROC integral:\", max_roc)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_path = \"dnn_params2.txt\"\n",
    "params = get_params(params_path)\n",
    "training_path = \"dnn_training2.txt\"\n",
    "training = get_params(training_path)\n",
    "configs = [\"PreSel_0tag_Xtohh1000\", \"PreSel_1tag_Xtohh1000\", \"PreSel_2tag_Xtohh1000\", \n",
    "           \"QCDCR_0tag_Xtohh1000\", \"QCDCR_1tag_Xtohh1000\", \"QCDCR_2tag_Xtohh1000\",\n",
    "           \"SR_0tag_Xtohh1000\", \"SR_1tag_Xtohh1000\", \"SR_2tag_Xtohh1000\",\n",
    "           \"PreSel_0tag_Xtohh2000\", \"PreSel_1tag_Xtohh2000\", \"PreSel_2tag_Xtohh2000\",\n",
    "           \"QCDCR_0tag_Xtohh2000\", \"QCDCR_1tag_Xtohh2000\", \"QCDCR_2tag_Xtohh2000\",\n",
    "           \"SR_0tag_Xtohh2000\", \"SR_1tag_Xtohh2000\", \"SR_2tag_Xtohh2000\"]\n",
    "s_end = \"_s.root\"\n",
    "b_end = \"_b.root\"\n",
    "comp_params_path = \"comp_params.txt\"\n",
    "comp_params = get_params(comp_params_path)\n",
    "model_input_path = \"dnn_model2.csv\"\n",
    "model_input = get_params(model_input_path)\n",
    "model_name = \"model_dense.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 1,522\n",
      "Trainable params: 1,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8365 samples, validate on 3523 samples\n",
      "Epoch 1/300\n",
      "8365/8365 [==============================] - 3s 302us/step - loss: 0.2807 - binary_accuracy: 0.8849 - val_loss: 7.4147e-04 - val_binary_accuracy: 0.9747\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00074, saving model to dataset/weights/TrainedModel_Keras_Dense.h5\n",
      "Epoch 2/300\n",
      "8365/8365 [==============================] - 1s 68us/step - loss: 0.1406 - binary_accuracy: 0.9598 - val_loss: 4.7655e-04 - val_binary_accuracy: 0.9776\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00074 to 0.00048, saving model to dataset/weights/TrainedModel_Keras_Dense.h5\n",
      "Epoch 3/300\n",
      "8365/8365 [==============================] - 1s 71us/step - loss: 0.1221 - binary_accuracy: 0.9638 - val_loss: 4.2406e-04 - val_binary_accuracy: 0.9790\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00048 to 0.00042, saving model to dataset/weights/TrainedModel_Keras_Dense.h5\n",
      "Epoch 4/300\n",
      "8365/8365 [==============================] - 1s 68us/step - loss: 0.1104 - binary_accuracy: 0.9675 - val_loss: 2.8738e-04 - val_binary_accuracy: 0.9821\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00042 to 0.00029, saving model to dataset/weights/TrainedModel_Keras_Dense.h5\n",
      "Epoch 5/300\n",
      "8365/8365 [==============================] - 1s 70us/step - loss: 0.0997 - binary_accuracy: 0.9710 - val_loss: 2.7540e-04 - val_binary_accuracy: 0.9824\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00029 to 0.00028, saving model to dataset/weights/TrainedModel_Keras_Dense.h5\n",
      "Epoch 6/300\n",
      "8365/8365 [==============================] - 1s 69us/step - loss: 0.0960 - binary_accuracy: 0.9720 - val_loss: 2.9537e-04 - val_binary_accuracy: 0.9821\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00028\n",
      "Epoch 7/300\n",
      "8365/8365 [==============================] - 1s 71us/step - loss: 0.0925 - binary_accuracy: 0.9721 - val_loss: 2.6325e-04 - val_binary_accuracy: 0.9830\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00028 to 0.00026, saving model to dataset/weights/TrainedModel_Keras_Dense.h5\n",
      "Epoch 8/300\n",
      "8365/8365 [==============================] - 1s 70us/step - loss: 0.0913 - binary_accuracy: 0.9729 - val_loss: 2.6086e-04 - val_binary_accuracy: 0.9827\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00026 to 0.00026, saving model to dataset/weights/TrainedModel_Keras_Dense.h5\n",
      "Epoch 9/300\n",
      "8365/8365 [==============================] - 1s 78us/step - loss: 0.0874 - binary_accuracy: 0.9741 - val_loss: 2.9100e-04 - val_binary_accuracy: 0.9827\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00026\n",
      "Epoch 10/300\n",
      "8365/8365 [==============================] - 1s 69us/step - loss: 0.0869 - binary_accuracy: 0.9741 - val_loss: 2.6700e-04 - val_binary_accuracy: 0.9824\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00026\n",
      "Epoch 11/300\n",
      "8365/8365 [==============================] - 1s 68us/step - loss: 0.0839 - binary_accuracy: 0.9744 - val_loss: 2.8789e-04 - val_binary_accuracy: 0.9847\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00026\n",
      "Epoch 12/300\n",
      "8365/8365 [==============================] - 1s 73us/step - loss: 0.0828 - binary_accuracy: 0.9743 - val_loss: 2.7944e-04 - val_binary_accuracy: 0.9833\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00026\n",
      "Epoch 13/300\n",
      "8365/8365 [==============================] - 1s 80us/step - loss: 0.0795 - binary_accuracy: 0.9748 - val_loss: 2.5684e-04 - val_binary_accuracy: 0.9810\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00026 to 0.00026, saving model to dataset/weights/TrainedModel_Keras_Dense.h5\n",
      "Epoch 14/300\n",
      "8365/8365 [==============================] - 1s 70us/step - loss: 0.0809 - binary_accuracy: 0.9737 - val_loss: 2.7328e-04 - val_binary_accuracy: 0.9833\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00026\n",
      "Epoch 15/300\n",
      "8365/8365 [==============================] - 1s 76us/step - loss: 0.0792 - binary_accuracy: 0.9753 - val_loss: 3.2594e-04 - val_binary_accuracy: 0.9838\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00026\n",
      "Epoch 16/300\n",
      "8365/8365 [==============================] - 1s 76us/step - loss: 0.0792 - binary_accuracy: 0.9747 - val_loss: 2.8606e-04 - val_binary_accuracy: 0.9833\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00026\n",
      "Epoch 17/300\n",
      "8365/8365 [==============================] - 1s 76us/step - loss: 0.0787 - binary_accuracy: 0.9751 - val_loss: 2.7633e-04 - val_binary_accuracy: 0.9824\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00026\n",
      "Epoch 18/300\n",
      "8365/8365 [==============================] - 1s 71us/step - loss: 0.0757 - binary_accuracy: 0.9751 - val_loss: 3.5456e-04 - val_binary_accuracy: 0.9835\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00026\n",
      "Epoch 19/300\n",
      "8365/8365 [==============================] - 1s 73us/step - loss: 0.0753 - binary_accuracy: 0.9763 - val_loss: 2.6949e-04 - val_binary_accuracy: 0.9824\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00026\n",
      "Epoch 20/300\n",
      "8365/8365 [==============================] - 1s 73us/step - loss: 0.0743 - binary_accuracy: 0.9754 - val_loss: 3.8261e-04 - val_binary_accuracy: 0.9835\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00026\n",
      "Epoch 21/300\n",
      "8365/8365 [==============================] - 1s 73us/step - loss: 0.0728 - binary_accuracy: 0.9757 - val_loss: 2.7963e-04 - val_binary_accuracy: 0.9818\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.00026\n",
      "Epoch 22/300\n",
      "8365/8365 [==============================] - 1s 70us/step - loss: 0.0720 - binary_accuracy: 0.9763 - val_loss: 2.7090e-04 - val_binary_accuracy: 0.9790\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.00026\n",
      "Epoch 23/300\n",
      "8365/8365 [==============================] - 1s 70us/step - loss: 0.0729 - binary_accuracy: 0.9743 - val_loss: 2.7873e-04 - val_binary_accuracy: 0.9815\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00026\n",
      "Epoch 00023: early stopping\n",
      "cut: 0.9337720922392972\n",
      "ROC integral: 0.9416964464904529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9416964464904529"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         : \n",
      "                         : Evaluation results ranked by best signal efficiency and purity (area)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet       MVA                       \n",
      "                         : Name:         Method:          ROC-integ\n",
      "                         : dataset       Keras_Dense    : 0.942\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "                         : Testing efficiency compared to training efficiency (overtraining check)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) \n",
      "                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   \n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : dataset              Keras_Dense    : 0.000 (0.413)       0.893 (0.825)      0.991 (0.986)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning in <TCanvas::Constructor>: Deleting canvas with same name: ROCCurve dataset class 0\n"
     ]
    }
   ],
   "source": [
    "params_ = \"H:!V:VarTransform=N_AllClasses:FilenameModel=model_dense.h5:NumEpochs=300:BatchSize=64:TriesEarlyStopping=10\"\n",
    "model_input_ = \"3,20,2,he_uniform,relu,elu,softmax\"\n",
    "comp_params_ = \"binary_crossentropy,binary_accuracy\"\n",
    "training_ = \"nTrain_Signal=8014:nTrain_Background=351:SplitMode=Random:NormMode=NumEvents:!V\"\n",
    "model_name_ = \"model_dense.h5\"\n",
    "comb = \"COMB5\"\n",
    "DNN(params_, training_, model_input_, comp_params_, model_name_, configs[17], comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_opt(configs[17], params, training, model_input, comp_params, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add weights\n",
    "def v_out(tree, not_cons, variables, reader):\n",
    "    \n",
    "    h = ROOT.TH1D(\"\",\"\",60,-1,1)\n",
    "    \n",
    "    nevt = tree.GetEntries()\n",
    "\n",
    "    vout = np.arange(nevt, dtype='float').reshape(1, nevt)\n",
    "\n",
    "    for ievt, entry in enumerate(tree):\n",
    "        i = 0    \n",
    "        for branch in tree.GetListOfBranches():\n",
    "            name = branch.GetName()\n",
    "            if name in not_cons:\n",
    "                continue\n",
    "            variables[i][0] = getattr(entry,name)\n",
    "            i += 1\n",
    "\n",
    "        vout[0,ievt] = reader.EvaluateMVA(methodName)\n",
    "        h.Fill(vout[0,ievt])\n",
    "    \n",
    "    return h, vout, variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_report_pred(background, signal, data, sep):\n",
    "    background = list(background[0])\n",
    "    signal = list(signal[0])\n",
    "    data = list(data[0])\n",
    "    bakg_t = [0]*len(background)\n",
    "    signal_t = [1]*len(signal)\n",
    "    y_predicted = background + signal\n",
    "    y_test = bakg_t + signal_t\n",
    "    for i in range(len(y_predicted)):\n",
    "        if (y_predicted[i] < sep):\n",
    "            y_predicted[i] = 0\n",
    "        else:\n",
    "            y_predicted[i] = 1\n",
    "    for j in range(len(data)):\n",
    "        if (data[j] < sep):\n",
    "            data[j] = 0\n",
    "        else:\n",
    "            data[j] = 1\n",
    "    print(classification_report(y_test, y_predicted, target_names=[\"background\", \"signal\"]))\n",
    "    print(\"Accuracy total:\", accuracy_score(y_test, y_predicted))\n",
    "    #print(\"Confusion matrix:\", confusion_matrix(y_test, data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(config, type_signal, methodName, sep, comb):\n",
    "    reader = TMVA.Reader( \"!Color:!Silent\" )\n",
    "    \n",
    "    dataPath = config + \"_\" + type_signal + \"_d.root\"\n",
    "    bkgPath = config + \"_\" + type_signal + \"_b.root\"\n",
    "    sigPath = config + \"_\" + type_signal + \"_s.root\"\n",
    "    \n",
    "    print(dataPath)\n",
    "    \n",
    "    dataFile = ROOT.TFile(dataPath)\n",
    "    bkgFile = ROOT.TFile(bkgPath)\n",
    "    sigFile = ROOT.TFile(sigPath)\n",
    "\n",
    "    dataTree = dataFile.Nominal\n",
    "    bkgTree = bkgFile.Nominal\n",
    "    sigTree = sigFile.Nominal\n",
    "    \n",
    "    # Add Variables: We add variables to the reader exactly in the same way we did for the **DataLoader** during the training\n",
    "    # We need to specify the address of the variable in order to pass it to TMVA when we iterate on the TTree\n",
    "    variables = []\n",
    "    i = 0\n",
    "    \n",
    "    not_cons = ['sample', 'EventWeight', 'EventNumber', 'm_region', 'm_FJNbtagJets', 'm_FJphi', 'm_FJeta', 'm_DTeta', 'm_DTphi']\n",
    "    \n",
    "    for branch in dataTree.GetListOfBranches():\n",
    "        if branch.GetName() in not_cons:\n",
    "            continue\n",
    "        aux = array('f',[0])\n",
    "        variables.append(aux)\n",
    "        reader.AddVariable(branch.GetName(),variables[i])\n",
    "        i = i+1\n",
    "    \n",
    "    # Setup Classifiers: We set up the classifiers by reading the input weights from the appropriate files\n",
    "    # The file is stored for example as *dataset/weights/TMVAClassification_BDT.weights.xml\n",
    "    weightfile = \"dataset/weights/TMVA_Higgs_Classification_\"+ config + \"_\" + type_signal + \"_\" + comb + \"_\" + methodName + \".weights.xml\" #_\" + config + \"_\" + type_signal + \"_\" + comb + \"_\" + methodName + \"\n",
    "    name = ROOT.TString(methodName)\n",
    "    reader.BookMVA( name, weightfile )\n",
    "    \n",
    "    # We iterate on the input event in the given TTree. We provide as input first the background tree \n",
    "    # We return the output results for the various methods in big numpy array [ number of methods x \n",
    "    # number of events]\n",
    "    # We also fill an histogram for each method.\n",
    "    # Note that is important to fill the arrays with the tree entries in order to pass the values to \n",
    "    # the TMVA::Reader\n",
    "    variables2 = variables\n",
    "    \n",
    "    hd, d_vout, variables = v_out(dataTree, not_cons, variables, reader)\n",
    "    hs, s_vout, variables = v_out(sigTree, not_cons, variables, reader)\n",
    "    hb, b_vout, variables = v_out(bkgTree, not_cons, variables, reader)\n",
    "    \n",
    "    print(\"Signal size:\", len(s_vout[0]))\n",
    "    print(\"Background size:\", len(b_vout[0]))\n",
    "    \n",
    "    # Classification report\n",
    "    prediction = gen_report_pred(b_vout, s_vout, d_vout, sep)\n",
    "    \n",
    "    print(\"Prediction size:\", len(prediction))\n",
    "    \n",
    "    # Histogram\n",
    "    c1 = ROOT.TCanvas(\"c1\", \"c1\")\n",
    "    c1.cd()\n",
    "    hb.Draw()\n",
    "    hs.SetLineColor(ROOT.kRed)\n",
    "    hd.SetFillColor(ROOT.kGreen)\n",
    "    hb.SetFillColor(ROOT.kBlue)\n",
    "    hb.Draw()\n",
    "    hs.Draw('Same')\n",
    "    hd.Draw('Same')\n",
    "    hb.SetTitle(\"background\")\n",
    "    hs.SetTitle(\"signal\")\n",
    "    hd.SetTitle(\"data\")\n",
    "    c1.BuildLegend()\n",
    "        \n",
    "    img_file = config + \"_\" + type_signal + \"_\" + comb + \"_\" + methodName + \"_hist.png\"\n",
    "    c1.SaveAs(img_file)\n",
    "    \n",
    "    dataFile.Close()\n",
    "    sigFile.Close()\n",
    "    bkgFile.Close()\n",
    "    \n",
    "    display(Image(filename=img_file)) \n",
    "    \n",
    "    return prediction, d_vout[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def predict_test(config, type_signal, methodName, sep, comb):\n",
    "    \n",
    "    reader = TMVA.Reader( \"!Color:!Silent\" )\n",
    "    data_input = config + \"_\" + type_signal + \"_\" + comb + \"_DNN_Classification.root\"\n",
    "    data = ROOT.TFile(data_input)\n",
    "    testTree = data.Get(\"dataset/TestTree\")\n",
    "    \n",
    "    array_ = tree2array(testTree)\n",
    "    className = pd.DataFrame(array_)\n",
    "    className = className['className']\n",
    "    true = []\n",
    "    \n",
    "    for el in className:\n",
    "        if el == b'Background':\n",
    "            true.append(0)\n",
    "        else:\n",
    "            true.append(1)\n",
    "    \n",
    "    variables = []\n",
    "    i = 0\n",
    "    \n",
    "    not_cons = ['classID', 'className', 'weight', 'Keras_Dense']\n",
    "    \n",
    "    for branch in testTree.GetListOfBranches():\n",
    "        if branch.GetName() in not_cons:\n",
    "            continue\n",
    "        aux = array('f',[0])\n",
    "        variables.append(aux)\n",
    "        reader.AddVariable(branch.GetName(),variables[i])\n",
    "        i = i+1\n",
    "    \n",
    "    weightfile = \"dataset/weights/TMVA_Higgs_Classification_\"+ config + \"_\" + type_signal + \"_\" + comb + \"_\" + methodName + \".weights.xml\" #_\" + config + \"_\" + type_signal + \"_\" + comb + \"_\" + methodName + \"\n",
    "    name = ROOT.TString(methodName)\n",
    "    reader.BookMVA( name, weightfile )\n",
    "    \n",
    "    ht, t_vout, variables = v_out(testTree, not_cons, variables, reader)\n",
    "    \n",
    "    pred = []\n",
    "    for el in t_vout[0]:\n",
    "        if el <= sep:\n",
    "            pred.append(0)\n",
    "        else:\n",
    "            pred.append(1)\n",
    "    \n",
    "    print(\"Test set size:\", len(t_vout[0]))\n",
    "\n",
    "    print(classification_report(true, pred))\n",
    "    print(\"Accuracy:\", accuracy_score(true, pred))\n",
    "    matrix = confusion_matrix(true, pred)\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(matrix[0])\n",
    "    print(matrix[1]) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR_2tag_Xtohh2000_d.root\n",
      "Signal size: 11449\n",
      "Background size: 439\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " background       0.23      0.79      0.35       439\n",
      "     signal       0.99      0.90      0.94     11449\n",
      "\n",
      "avg / total       0.96      0.89      0.92     11888\n",
      "\n",
      "Accuracy total: 0.8924966352624495\n",
      "Prediction size: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArgAAAHYCAIAAAApvgy/AAAABmJLR0QAAAAAAAD5Q7t/AAAgAElEQVR4nO3dT47cxv338arnl4ME0CiyfAmSQDCxtJEjXSArBxEc2yvbsGOTTOLAzip2gASaVQ4Q/8kiMaINizmELUE2kJvwWXwz5Zoiq5rdzSaL7PcLgjDDZrOLPd1dn65/1F3XKQAAgCH/b+kCAACAdBEUAABAEEEBAAAEERQAAEAQQQE4rVdffVVr/c4778zzcA8fPtRav//++/M83LK01j/5yU+WLgWwcQQF4LSePXs258N9++23cz7c4l68eLF0EYCNIygAAIAgggIAAAj60dIFAM6LDFb45JNPQju8+eab9udPP/00tNuHH34oP/z2t789uDCPHz+WH/7yl7/E9/zNb36jlPr973/vbnz33Xflh48//vjgMrh+/etfK6X+/Oc/h3Z46623Xrx4cfv27T/96U+TPCKA3ToAp3Tnzh2l1Ntvvy0/WHfu3PH2fOONN/rv0DfeeMPb7YMPPvD2efTokb31pZdeUkq99957dst7770nu7kbf/WrX3kHsVtkBxkO+fDhQzsu8u7du/buDx488O7+4MEDt5A///nPvUcU3sfOxcWF/Co/WBcXF94d79+/7z2iTVSxZx/A0XiPAafl5oM7d+48ePDA3WJ3synh4uLi3r179+7ds3WnmxVsSrh79+6jR48ePXrkZQUvKMRTwq1bty4vL2/duuVWwLKP5IO7d+/ah3v48KF3Rt7puFlhr6Ag/7/yyiuvv/76K6+8Ivu88sordjebEm7fvn3//v3bt2/3CwzgRHiPAac1WI++/fbbsvHtt9+WLVJZ3rt3z71vf6Pc64MPPrBbbHSQX92gMJgS7EEuLy/7G72goG42JHRdZ+d5vvPOO/2NdsteQcGr7G1W8O715ptv2i1uB00H4JR4jwGnZYOCt9223suv0org7XPv3j03KEj7gVdzd10n3/slPdigEEoJXheDdXl5ORgUBk/H62job98rKLiNB/3dpDnh9u3b3j62XaEDcEoMZgTm0O/U/+qrr7TW9td//etf3g5vvvnm4CIBL7/8srflm2++8bZ8++23X375pfz80UcfuTd9//33SikbCyyvAyLk+fPnSimJI65XX331k08+OWzRCG+AgkeehP4Yhfv370cGewKYCtMjgTl4IxlDpANea621/uyzz7777jv3VgkE/aDQZ1OCUurhw4djHnpw4oMdo+AJTXOQGDGt0JJKTHwA5kFQAJJw//59rfXXX3/93XffXVxcXFxcvPHGG9L1cJjueoyCGxrUdYvC5KaaIRlCLACWQlAA5rDzq/bXX3+trocjvHjx4sWLF6F29X5HQ59EhI8++kj6CNyGgVAXg11TYQy7goK3ZWTDyV5kLMJbb73lbe9vAXAKBAVgDv3O+1dffVVd16wyhv/i4qI/UsElnQ79oPDyyy9rre0STC659MOzZ8/s4EQJCk+fPvX2HNnSIAXun85XX32lemMXvAtPHHapKgkK/WeGqzwA8yAoAHN4/vy5dwHJf/zjH+rmIEdvRIK6bmaw/v73vyulvv32Wy8TSH0cWqJRJiD84Q9/kF/tWASvCaEfHQZJvpHCuwYHOXpB4YsvvhjzEJ5//vOfSqkXL154TQjxUAVgKsx6AGbyxz/+8fnz53fu3Hn+/LmtaGUt508//fSzzz5T14MZlVIvXrywKcH96vzo0aPPP//8d7/73TfffPPyyy9/8803n3/+uWwPPe4XX3wh0yvu3r0rNffl5eXTp0//+te/fv/997du3fr+++9HpgSl1Mcff/zVV189f/5ca/3gwYOXXnrp2bNncjp37tyxIxXu3r375ZdfPnv27OHDh9Lx8cUXXxx8Ic3bt29LX4ys3/zixQtSAjCfpednAhtnl3D23nreEs799ZtlGeP+W7WfCdyVFfpLOHdDKy/1p0cOLuHcX7PBPSlXf2UFaclwvffee1I8u49MjHz99de9+/Y/nbzVGBVLOANz0Z3zSQTgpN555x1por9z587gdaHs4kJ2JKNdTcH7Dv3hhx/a2ZIHXxfq8ePH0qgg/RHS8DD+M+Hdd9999uzZSy+9FJry8P7779veh8P6HTxyUSh13R8BYAYEBeDsXFxc3Lp169///re78Wc/+9nTp08vLy+97QDOHIMZgbMjgxIGBzOOXJ8RwPmgRQE4O48fP/7rX/8qP0sykLmRt27d6s+8AHDmCArAOXr8+PHTp0/dtRPodAAwiKAAAACCGKMAAACCCAoAACCIlRkBABOTNTmQuJFjDwgKAIDpMQAucePDHF0PAAAgiKAAAACCCAoAACCIoAAAAIIICgAAIIigAAAAgggKAAAgiKAAAACCCAoAACCIoAAAAIIICgAAIIigAAAAgggKAAAgiKAAAACCCAoAACDoR0sXYGLjL7ANANgOrVXXLV2IbdpaUFBKdbxWAGBRfGfbkg0GBQDA4mbOCh3p5GQICgCA6c3duKs1zcl7GZ+rGMwIAACCCAoAACBog10PoeYUWqUAYFnGmKqq+tvzPB/cPlJ1zJ3XwBiT53l/o1Kqvz20/8E22KLQBSxdLgA4d8aYtm0Pu2+e51I1Dh724CKlr6qqoijcLXmea62LoiiKQmvtnr69SWs9VVbYYIsCACBlh9XrkYRhjFEbnfJgjKnr2t1SVVXbtk3TSA6QWCBfhvM8926KpKvxkm5RkEaqqqr651lV1STnDwBIh/Qh2A9/b7utDuxuUiOG6oh+j4TdvpbqoyiKLMvcLXVdZ1lmWwvKsrQ3tW1blqW9qWmag9tvbgg11C9OTj7LMnmOyrK0N0nJZXuWZe69Uj4jADgToY9i+WAP3atpGlvz2dpRbsqyrFNqxz/nIP0jdDfrDq9aSZPUgHJGdmPTNE3T2F/dp1TCgbunt8U1vrpMt1p1T899mrzXmfcsEBQAYHHxoJD1yMe4fNS7X/9uVOfOp72XALzK0juC/OrVmvK4R57mSdmT8oKCu4P3RdpLP3KE44NCol0P3mBO+cG2NbntMFmWbX24KwCckZEf6W6TuyV1h9utUJal2/xubzLGpNz7IEMTbOvIoLqu5dTcboi6rqVjpaoqb3DDwdY3mFH6YOyveZ5P9VwAAGYQr6GPH6s/OEk+z/Msy+q6tn38KX/JLIrCHW0wSFoFZE6EDGCUM5JzVEo1TeNNlzhMoi0KbhOCctoSxtxX7+80JwEAOJVIJdr0yHZjjG2Qr+s68Q9/KaFMalDXVZvqVYVe/VhVldu5oKYIXokGBaVU0zT2aYosK9E3stPF66oBAGxGfk05/RHu1AlJD8n2Prgpxw41kDIXRdFvC7Hfrt2bpjq7dLse8jzvus5GhMSjHwBgpMEKbMxXwZ0LDkr/gl1XwBhjpxdKr7+XHiZcvnBaXsGk5PKzdKDYQCDb7a32HOV8B0dy7O2A79/z8CauqOuhm95QVe/XlM8IAM5E6KM4Um91Q8P71c1ZD+p6CoO6OZi/PxvO8uoL96b0p0eKwafF5U39Gzz3vvHVZbrX5dRaZ1nmhj7bfGQHbrg/23sle0bAKmh9Fbm1616brSRYr5N8FGttmkaNbnuQH7ydQ9tXJ3IiIxtLxv+N0q1WJQTYX91yurM+yrJ0u2QICsCRtL5SKpQGrggKGONEQUHx8T6dLQQFse/VsQgKwJEICjgeQSF94/9G6Q5mFJHGk7U3HAEAkL7Ug8IBQvMjaGkAAGBfGwwKBAIAAKaS7oJLAICNkas8h9ZROJ8O5X2vNNHf2Vzb616H2drQPwYzAkdiMCOOF/oolq5hO/XdstPcYh/gWxnMmOe5vU6VN3Evsr/7zLhHUEq5awRY7hIDg8ZXl7QoAABm5VZyIuXrM02rqqq2bWWJJLnYY/x7v+wfOkLXdbISpXevidtmRi7MtBbbOyNgZko9UaoL/HuydOmwDqGPYqWULI/oLibobnc3ymUOyrL8387Xt8r2LMt+uOl6u62A5dapTmdC6uaKkCq6fqKsyeg9M95dZJ/+OpXxI3f7VJdbq1YJCsCRCAo4XjwoeEvv26rOvZfUjnbR5bIsO2eZZ/cm97u1vZf94WSneIh+pd6PRy45cW+B6izLvHikeqs4N03jPcmDBx9Z7K1VqwQF4EgEBRwvHhT6mcDb6FWN//tVqS56uR+vrSJeBy+if9UG70xd9tQi+3S907QtFhMGhQ2OUdABS5cLAKDUzcv3KKXatvXGKNR17V7Aybt0stup7/XfZ1lmu+cTnEMxfhqCMaZt252TGrTWMl5BttjraB9RxgEbDAqR9AQASEGWZVKfhdbpb9s29E1P5liu8Rvg+Owi1zuMH0quoN11nQ1edV3H73WYDS64BABIXFVVMla/qirv6s/CJokfFIW6nhkoswpXuvSCe6GiwTYD2ejNZXCnO0pC8mZFhu41ZgZmHEEBADA3qeHsTL/IPqKqKvlF9l9jPlBOn4stf9u2/ZyU57n7nHjPkty330wuycn+KolhkueKoAAAWECWZXVdq6EG+aZpiqKwFaq0IlTXt9rt0pE/2CCRLDlrdzCB/bpfVZUdgeE+J3L6XrbwGgnkV/de8rRMkqgICgCABUjvw2A1n+d5WZZuK3rTNNL1IIsUScKQxRKk3l3Lkk0yAtGOrijL0u2G6C9F1b+7UqptW2/Pk/bCbG3BY5ZwBo7EEs443lQfxTe+Xl8v4Wz79d3ZE+vqjEihzOP/RlurVgkKwJEICjjeST6Kt3Kth0SM/xttsOshNGGGAAEAwL42GBQIBAAATGWDCy4BAICpEBQAAEAQQQEAAARtcIwCACBlsrKQLByU5/n4JRDyPB9c89ibZ5hfO7Kcxxs5DTKy2+Q3HWLkVSbXYntnBMyMy0zjeJGPYql6yrIsy1JWW/IuG22vEz14z8gxs2v2IY44g2N561KP3M0ts3eT+7TIhacH7+XdFHwy96kut1atEhSAIxEUcLzQR7HU4u4WqQ5tfRar4KNBwbuX1JeRavLU3ADkhaHQbl6Z+zfJz/KM2fN1n9LITYMPPfZcRu63FufTdgKcCEEBx4vU6P0q07YiSHXoNSpI20PTNHsFhe66OnC3SBuG963dCxP9LQdw6/Xuuv7u79bfbk/EO8LOm9wncPCmvvHV4gYHM4ZOdelyAcC5y7KsbVtvUIJ7kSellN1BLotQ17Uxxrt68hheI7wcSilV17XWWh6rf2S5GNW+j+UxxrjXsLCXyvR2864S6R3B22KvMe3dy93TfRrVhCMVRgaKtdjeGQEzo0UBx4t8FLs132AzgN2ovOaHcJ2lhloU3O/rMnbB3mR/9To++t/ID+M9XKiEblFta0qoJP0qu3+vzmmVkaQSedDxZ5p0i4IxRi6w3c9Woe0AgJRJDSdNC/LlPjJu//hrQnqtFKKqKrn6ovdd32sJONjOi0D2CymtHW4J1fUsD9vi4qmqKnSd7omNDBTz82KRm5ik5P3tHS0KwNFoUcDxxn8Ue5/kKtwTv2+Lgj1CqHm/36+vJhr/OFg3jZmF4d7RLbaMrhgcEekOYBwcGxF63PF/o3SrVff03NYh74nw/q4EBeBIBAUcL/RRPDj70R2cbz/5BwYA7hkU7GFtfdnc5N7dNuOPO78dRnY99AdORuYpuM+Mdy8bLwYDSmTCRfQkfpB014NtTnHbVbymoSzLjm+bAgDMoG3bvbqMD+5flgWdpO6XGiR39I8szfje+MeD5Xnu9j6EulEigzQHuxtsR0mo1puk32TAyEAxPzlhiU6DeVP0GxhmLiewMbQo4Hihj+L+CDv5DHcHMLo/2+PsnB4pbRXSMDC4jpO6bn6WBob+AMBpqw8VHpVpm1W8rgHvV/debiXoLbfg/hq5abCEY89l5H6LcANNaDmOflDYUloC5kdQwPEin6v9b73uR3p/yMIPH9TRoBA55uDj9o8QaqI/TGRlRrd4XhvGYHwRbn3vnUv/CYw8D24xRp6L7lJdYEBrbaeNSqNQ0zR5nmuty7K0DS9ykz0LrdM9I2AVtL5S6rXAjVddF7oJ+MHOj2Lb8t9vYPdm///wq9bquI/3yIOeSMrXehhfXSZarUrPjVs2mw8ICsBJERRwvJN8FB8dFOAa/zdKejCjy7Yu2B/EVNNeAQBAX6JBob8Ihl0uQxbKsKtv9lcDBQAAU/nR0gUIapqmKAq7WFVZlnaKS1mWdkqJ3Q4ASIfWetoDdic4JsZIvUc/Plijv50xCsCRGKOARK1kjML2qqF0WxREpLWAhgQAAE4t9aBwgFDb1MYiHgAAM9hgUCAQAAAwlURnPQAAgBQQFAAAQBBBAQAABBEUAABAEEEBAAAEERQAAEDQBqdHso4CAABT2WBQIBAAADAVuh4AAEAQQQEAAAQRFAAAQBBBAQAABBEUAABAEEEBAAAEbXB6JOsoAAAwlQ0GBQIBAABToesBAAAEERQAAEAQQQEAAAQRFAAAQBBBAQAABBEUAABA0AanR7KOAgCsVeADHAvaYFAgEADAivEZnhi6HgAAQFCiLQrGmKqqvI15ntuNVVXJPnmez1s0AADOSKJBoa9tW/uzjELIsqwoiizLjDGLFQsAgE1LNCjkee5V/1pr2SKNCnYggmynXQEAgFNYxxiFPM/LspSfjTFZltmbsizrd1IAAIBJrCAoGGPatrVpoG1bt/0gz3O3VwIAAEwo0a4HV1EUTdOM3z+0jkIEMyoBABiUelCQhoS9hiBQ6wMAMJXUux7qurajEwAAwMySDgruNAfLmw/pjW0EAAATWkFQ8FRV1bat3OSNcwQAANNKeoxCXdf91gKZKlkUhfxaliWLKAAAcCJ6vUP/BtdZ0nrFZwSkQOsrpV4L3HjVdaGbgClovfaLQm2vGkq66yGOhgQAAE5txUEBAACcWtJjFA4TWnBpY21BAIClaH0VvvHJfOWYxQaDAoEAAHB6ofE6OnzTKtH1AAAAgggKAAAgiKAAAACCCAoAACCIoAAAAIIICgAAIGiD0yNZRwEAgKlsMCgQCAAAmApdDwAAIIigAAAAgggKAAAgiKAAAACCCAoAACCIoAAAAII2OD2SdRQAAJjKBoMCgQAAgKnQ9QAAAIIICgAAIIigAAAAgggKAAAgiKAAAACCCAoAACBog9MjWUcBAICpbDAoEAgAAJgKXQ8AACAo9aBQVVWe51VVDW43xixQJgAAzkbSXQ8y2iDLsrqujTE2FtjtRVFkWUZcAADgRNJtUcjzPMuyruuMMU3TtG0rgUBaF2R713V2OwAAmFy6LQpt2zZNIz/neW6HKBpjsiyzu2VZVlUVWQEAgFNINygopdzRCfaHtm3LsnT3qet69qIBAHAWEg0K0kKgtZbGg7Zt67oeOe8xtI5CBDMqAQAYlO4YBaVUWZYyhlEq8v7ch0Hd/k57GgAArFbSQcFNBsxuAABgfokGhTzP1XUHhGjbVn7wEoM3thEAAEwo0aCgrqczyM/uxMiqquyUSGNM27YjuyQAAMC+Eh3MqJQyxmit7cjEsiylmSHP87Isi6LwtgMAgMnpxIfyScvBYBQwxvS3a536GQGJ0/pKqdcCN151XegmYApaqzV8hkffJlurhtJtURCR1gIaEgAAOLXUg8IBQusobCziAQAwgw0GBQIBAABTSXfWAwAAWBxBAQAABBEUAABAEEEBAAAEERQAAEAQQQEAAARtcHok6ygAADCVDQYFAgEAAFOh6wEAAAQRFAAAQBBBAQAABBEUAABAEEEBAAAEERQAAEDQBqdHso4CAABT2WBQIBAAADAVuh4AAEAQQQEAAAQRFAAAQBBBAQAABBEUAABAEEEBAAAEbXB6JOsoAAAwlQ0GBQIBAABToesBAAAEpRsUjDH5Te6tVVXleW6MWaZwAACch6SDQtu2gzdpreu6VkoVReEFCAAAMKF0xygYY7Is67cZVFWlnIEIWmtpe5i1cAAAnId0WxTath2s/iVA2F+zLJPoAAAAJpduUFBKGWO01lprdziCFyDyPA/1UAAAgCMlHRSUUk3TNE2jlCqKYuRd9P5OeQYAAKxYumMU3OUQpGmhqqoxvQysowAAwFRSb1GwBgc2AgCAk0o0KPQnMtihCV5i8MY2AgCACSUaFGSIou1okB8kKFRV1batZAVZa4FZDwAAnEi6YxSapimKQhZWUkqVZSlBIc/zsizt2Ea7HQAATE4nPvRPWg5CCyr0t2ud+hkBidP6SqnXAjdedV3oJmAKWqs1fIZH3yZbq4bSbVEQkdYCGhIAADi11IPCAULrImws4gEAMIMNBgUCAQAAU0l01gMAAEgBQQEAAAQRFAAAQBBBAQAABBEUAABAEEEBAAAEbXB6JOsoAAAwlQ0GBQIBAABToesBAAAEERQAAEDQBrseAJyO1lehm7iwJMYKjCRDmggKAMaLRIFggAAGMJhsPeh6AAAAQQQFAAAQRFAAAABBGxyjwIJLAABMZYNBgUAAAMBU6HoAAABBBAUAABBEUAAAAEEEBQAAEERQAAAAQQQFAAAQtMHpkayjAADAVDYYFAgEAABMha4HAAAQtI6gkOe5t6WqqjzPjTELlAYAgLOxgqCQ53nbtm4m0FrXda2UKoqinyEAAMBUUh+jYIxp29bdUlWVcgYiaK2NMcQFAABOIfUWhaIoyrJ0txhjsiyzv2ZZJtEBAABMLumgkOd5WZZeDmjb1m0/kI6JmQsGAMCZSLfroaoqb2jCSKF1FCKYUQkAwKBEg4Ixpq7rw+pvan0AAKaSaFCQ7ga3i6EoiizLmA8JAMCc0g0KbiZo29YOWvTigje2EQAATEivoqFea900jTQwGGOKopBf3Z/tnqs4IyBZWl8p9dr+97vqugPuhbOktVr5B3X0bbK1aijRFoUImQpRFIX8WpYliygAAHAiKw4+g+ss0aIAHIkWBZwcLQqrkvQ6CnE0JAAAcGrr63rYKbSOwsYiHgAAM9hgUCAQAAAwlRV3PQAAgFMjKAAAgCCCAgAACCIoAACAIIICAAAIIigAAICgDU6PZB0FAACmssGgQCAAAGAqdD0AAIAgggIAAAgiKAAAgCCCAgAACCIoAACAIIICAAAI2uD0SNZRAABgKhsMCgQCAACmQtcDAAAIIigAAIAgggIAAAgiKAAAgCCCAgAACCIoAACAoA1Oj2QdBQAAprLBoEAgAABgKnQ9AACAoKSDgjGmqqo8z40x3k2h7QAAYELpBoWqqoqikChQFEWe5/YmrXVd1/3tAABgWumOUajrumkayQHGmKIoZHtVVcoZiKC1NsYQFwAAOIVEWxSkIcFW/zYuyP9Zltk9syyT6AAAACaXaFDI89y2GdgGA/m/bVu3/SDP87Zt5y8hAADnIN2uB2FzQNM0I+8SWkchghmVAAAMSj0omGtFUdghC3HU+gAATCXRrgdXnucyCoHJkAAAzCzRoFBVVagHIcsyNzF4YxsBAMCE0g0K9n91cxJEVVVt29oZEG3bMusBANKidewfViXdMQplWdZ1LQsrya927kNZlnZZBbsdAJAQhotthU586J+3oIJ3U3+71qmfEZA4ra+Uem3/+1113QH3wkZpve2gEH2bbK0aSrdFQURaC2hIAADg1FIPCgcIjYLcWMQDAGAGGwwKBAIAAKaS6KwHAACQAoICAAAI2mDXA4BFaH0VuokJEcB6ERQATCISBYIBAkD66HoAAABBBAUAABC0wa4H1lEAAGAqGwwKBAIAAKZC1wMAAAjaYItCqOsBOB3asQBs1QaDguJTG/MimwLYMLoeAABAEEEBAAAEERQAAEDQGQUFref7F1FVldY6z/OZTvumPM+11lVVLfLoSdFaa62NMUsXBACSdkZBAQAA7IugAAAAgggKAAAgaJvrKAAAphEfdcWiNWeAFoUlycBGKzTG0NstPhpRhiuKPM9HDtbL8zzP8/5hvaMppYwx3p5yX3tTv3he+QcHclZVFSqtPb5wC2Afca8nkLGcwH66bvgfzkS3LZGTUmq+fxFlWSqlsizLsqz/58iybPCMxuzZNM3OPeVBy7IcfIgxR7Pl7z/n7j47y980jftwgwXzju8WLMuyUAnHPIH2yfeKcZj+g66aUk+mfkc8WfqccITIy/uwmzYh+jbZ2rnTorCMtm3btpXaruu6pmmk6mrb1vuyLj+4NahU1W3bet+/i6KQH2zlF9rTZZcf7m7WqaGj1XUdOU6WZWVZ2lPol9/W7kVRHDM1sW3boij6GUgp5R7WFsB9quXuBz80AJyX0+aQ2UVOKqkWBTXUJGCrOu90+t+z+9+/7WEH97SP5d0x9DIIHW2w8PYg3rdzmwn65e8fZN8WhcEnsP9w8QL0y3yYjb2PaFHADefaoqDUk13/zqVFYXPns56gMFhFeTeVZTlYd3rVfxeuEW216t5RdouExdDRuqE6PrRzKG0M3nRAUOg/gd7TMqYABIU+ggJuOOugcNgLfvXn7qHrYTGRxRlt43lVVf2Rd8aYUMv54GhE+Ut7222Pg60yR5ZwcGjF4M5yFoP7TzKccOfqlqcuAACcg6SDgjFGBsP3P9Yjg+RXTWo177zs8yCD9u3oAXeHvR7FHWdQ13Xo7keuMy1pJn6Qk/4FxxQAABCX7joKVVXVdS0VZ13XdV3br8V23JwMZxtd2VwdVJBfKvVk3/torbrutcgOoe/lHmOMFwuyLJOEdORwPHne5JksisJtcog/n3meDz70YfWxzG884I4AphRfLAHnLd2gUNe1O35epr/bpng3NIyubGI197T32jnBOF7N29OxKcF9KtTR35JtumqaRh7C7eOwBx98Yse3AWRZtjPNnDQljCkAgP9hXQQEJN314NYitm4zxrhfx7Ms21J/s1ux2fPqui5+jvHq1luwyN0/z3PbZnNACcfY2T5xzN0PLsD2Oq0A4ETSDQpd17m1SNu28qv9QYRawtM3OErRvSkyFm/8YEbppIg8RfZBvVgWL+EY9u8VummMY2p0Kf/gMhJbCpcAcFLpBgXLdqVv7MPdGyPBM5IAAA/rSURBVEVohyPYZBCqaAefB7sa0uAqTPEhEf11mWwV6z1WfxxlRL8vQ9gBFv0JF17DhjFmfFNHX78HxysAgGNpPfwPW7LYxMxxBhcM6C805N4aOqnU1lEQspShW5HfLPP/lGXZNE2/ZnWXAfCO6e7sPZ+RBYi8PftHCy3hsPNk42fqrscsJ+uFm/6e/Yfrl809bL8AinUUhrCOwjna1mt4EqyjYCV9PoMf5WoTQcGryEP11uDlDJqmcbe7dxlsOejvEFmXyb2pfzQbVkYGha4XjGydPWZP2c07/l5BIVQAG0QICn0EhXO0rdfwJAgKlu5SHemqtR6c+mgvVDj4q3RSDJ7UnI1h459Ut30+1HM/uI8xRs7a6x0w1/Jre5S7xz6KfSAZFOLNwhh5nJ2lch/u+MK73NJO3oeldbrvowNofXXoFKGQq/hsYSxPa2Y9eI54I2zqA0Elez7SYV+WZX+4vtzUNI33s+ywuqCQJrdS926SZ3jfoLBtBIVdCArJIyj0EBR+sFxjRky8vdq9dfCKyYPHTKTrYRVCV0mINPufs409IXQ9nKNtvYYnQdeDteLgM7gcEC0KU3EvBmH7d2QOwj6rYZ4FWhR2oUUhebQo9NCiYG3ufMJBAXvprx4tSAl9BIVdCArJIyj0EBSsdJdwxrLkspN2EKK6Hl3IpRkA4KwQFBBDMsCpaR27WhtNEcDiCAoAFhdKA4dd8RXAlFawhDMAAFgKQQEAAATR9QDg5OIDEQCkjKAA4NQYkAisGF0PAAAgiKAAAACCCAqJMsZorfWc607vkmCRAACnRlAAAABBBIWkZVm2dBEAAGeNWQ+JkkstLF0KAMC5IygAAM4UK3yMQdfDMowxeZ7ra3mee9dulh2qqurf172j7FBVlbezezEn74HGlMceGQC27rXwPyillOq2ZRUnFRp5UJal3adpmv652I0eOWCWZXZP2R7af2R5Qo8++ROydht7TpR6olSXxr8nSz8ZZ2Nbr+HxTvNq39qTSYvC3Iwxbduqm7FAquq6ruP3LYpCfmiapuu6pmnkjnLA0P6yc+fU9G67wmB5yrKUW2lXAIAzR1CYm3QxZFnm1sG238HrgHDZ/buuk5peOiziMyPszrK/JAA3WMhhvfJUVSV7RsoDYBlax/4BUyMozC1U9co3/tAYAnXd3mC/6+88oBqaXdk/vmSCfsuB7BlqqwCwpK4b/gecAEFhbrYC7g9gjKQEa6++gDEHlFGQ3p7GGDodAACKoDC/qqrswIKiKGQmws5aOd4FEOp9GBMU3ILZiQ9FUdCWAABQ5xUU4h17gX/6oHvFewqNMXYcolKqbdu6rheckSjhoK5rGw6yLGNRSACAOq+gEOrVi/7rDrrXzs5C6XeQcQl22EFd1/NnBXuRp7Is7fwIuh4AAOKcgkKSpN9h5wxJ24kw2AdxcDeBPVrTNP2RCgAAEBTmFlr3cOQ3+P5uk8xgHJwNcfxhAQBrx7Ue5pZlmQxK8Gpiu55B6I5N08gYQ1lu2W63qzAdwzumXYUJWFZkKf6uY4XdISyl0MMFHY5EUJhbVVVStWut3dEJ9tbQHW1FXhRFlmUyysGtzg/oOHCPWZalHNM7bFVVtC5gIZEowEf/EJZSCCJWHuG0K0TPbhUn1V80SdixhF34wgr9Jgc7gcJdg7l/wNBhB68HIYfyfuVaDyEbe05SutYDl4EYsq3X2wxmf0lv7Q+0ghaFwW+0VVXJyPw1jr+rrtkt7sUe7ZZu6MuBuWYPNfgQg/cdPKxsscd0S9I0jd0YKRIAYMN04h/9xpiiKLy1jWVGn3T2Z1nmjuaTmxI/qcNIJuhHCnV91vEVoHE6Wqf+PtqL1ldraKe9WscYhfiIgdDLZuc4gw293mYw+0t6Ux8IKuUxCtJg0B9SJ/Wl/TNorb2BeFslQwfc5gRhGxXO4UkA1uewNLCtmgarlvT0SHu1Q5d3vUTvsocbJqdpLxIh8jwPXSwKAIDjpduiYNvYvTWI2rZ1K0VbU25enud2hqQ3JXLw8o8AABwv3aCAPhlOKJnADjMkIuAMdeqXSv8yfDPt9sBkCArrQzIAlDpiJCCAfSQ9RgEAACxrfUHBmw/pjW0EAAATWl/XgyyBLAP+Zcbg4NqCAFahU7GeAq2Cow1CC/gzPGGrdl6yYR1La6zQ+oKCzJm0w/7lCgWLlgjAUUJpIJ4hwkvohAc5YvW4/McCVhAU+ktcyfrHZ7LOEgAAC1rfGAWLlAAAwKmtoEUBAPbD6sjAdFbcorAvrfRs/w4roTFGa62ZBQ4cQasnquuC/wDs6YyCwubJZbSWLgUAYFPoetgOe7FN4gIAYCoEBQBQSh239vPKOzXiSxRMvj7BzA+HIxEUAODaYfX9RsYVharnE61PMPPD4XCMUVhMnuf6mqwyGdqzqip9k9e5UFVVnufS71DXdf+Skt4R4g8HAIBFUFiAzG6Qel20bSvrUvd31lrXde1tlDTgHtA7mj2UPJZ3BHk4hjIAAHbS/XUPV03mFg6e1MGzFg/QRdebtxMgy7KU2rqqKrcut+W37QR2T3fnpmncuCCHdfd0H8vuLJMj5LAb++svRetNvY+0vooulDuxTunDlnAOXwbiKtbJrXXs+tSBm3b0qccXjQ4/nFZPggcMv6IO6+DfeaGESF/AacYo7P1wu16Z8ROcc9zDpj4QlFKq25bISalOzfYvUsKyLKWQTdO4291LW3mnU5aldxC5YKa3vb/RHjP0RHllwGE29j5S6sl8b5X/1YfTHvNJ/PQOuGnXcxJ9xPBBI89J9H6RwgRLcsSf9aCz23HqM5/CzP829YHQdR2DGecmjQFZlnlLUA+uSC2pItRHsHOcgVxA64BCAgAgCArLGKz7y7L0BhMM7uaNSDjggRidAAAYiaAwK9sGMNh+kOd5f9yi3EuMzweTHwFQSh06aGBukf74Lnxr5KZjHjFSkmkPOL8TFXIV535Wziko6OFxQ7v8UgUGHMUeaqLhP8aYoijcLdJnMb7K94ZJ2iMMJhJgp8MGHs4r/tb7ZXiHyE3HPGKkJJMfc36Tl3MtJ35GzikodPG3ZcTedwzNerANCcaYfqNCf8yBTQneXIaRl9i2KSHLMllrwd5EUAAAjHFOQWFtbDLoDp1pY1MCyysBAA5DUJhblmWy3lG/+ve+5UvtLpMePXsNNRjZ/AAcKdL7kM7whaScor+GDn5MjqAwt6qqpEOhqqp4b4KsttTPBPvOWeg3J+iNLE2PhESiQErDFxJymvBEBz9OYOmFHCYWOak519uIF9JtJCjL0i51YLd7pyO7NU3TXxTBXTHJ3r1pGtnuHlnu7h1Bth/9rJ+7jb2PIsvadEod8H6I3+uwYx78L/JwM5dkPf82sALSzP829YHQdbuqtNVZRVDobmYFW2f3y+8u1+iGA3e7rendECBHizyQu/MRzze6jqCw61/8Xocd8+B/kYebuSTr+UdQ2Pffpj4QOlZmXIpx5NeU8sct5nnedZ3ta7C7KaWappE+BbtF5jV4G+2jeEdgzSUAIzHu4cxt7doVq7goFDZm5EWh1nLtKK21CryAIxdwiojf67BjKhUs5MGFObQkcQeWc3arKOcqCqm2V7FymWkAABBEUAAAAEFnNEaB7gBgjE4pNXU/XVIzJJMqDJC+MwoKAEaatqs+qdWWkioMsAp0PQAAgKC1tijI7D53uiCwGePnR5xiz9HGD0E/xZ7jUc4JraKQJ3r0tcy5mN76ZnHIlZdlHaG2bb3LKkamRwInMvn0yIWDgo7MEozPpw+tH7zspzZ7TrjnKgq5/J4bq4PWdz7ShCArCMlllN1T4CoGWMQZBYXQ5dr1E4LCGey5ikIuv+fqKta49Z2P1rppGtvj0P91FZ/Fq9hzFYVkT4ICe8645yoKufyeq6tY41Y2mNFbn9jdCAAAJrey4CMDFLy+hizLbFZgTXLgxAItCurJrKUAEtZ1m7re91pnPbjcBoaN/XmA9PAWA87LyroeAADAnFYWFNwpD95GAAAwuZUFBaVUlmVFUcjPdtmlBcsDAMCG/Z+7WtEq/OIXv6ivtW3bNM2Pf/zj0M5VVaUTI6qqkraQeIGrqvrvf/+7VLHHFNIY87e//W3nbic1ppxCSpvy82n/6PHd5jH+iZ3HWp7ALb0gF3+Dr+KjMi6pqmcC3To1TdM0zc59lFI7d5uBlCTLMllQsizLwd3kL2J3m7nkIwtZluWChexGl9OSneco2U2H/dF3ns7p7PvEJlKexZ/Ajb0gl32Dr+Kjcqd0qp6prDUoxDVNIy+gRP5a8oKWn+V92N/H2+7eZR5jCtl1nfuUypM8S+l+MLKcwn6gzFAwzwF/9J2nc1J7PbEzWMsTuKUXZLf0G3wVH5URqVU9U9lsUCjLUl5PKfy1vGIMlmrxV/8BhVzEmHIK97vRLEW7YUw5vbLJF5E5Cjdk/BM7j7U8gVt6QS7+Bl/FR2VEalXPVLYZFKwU/lr9D69Qk5psl16VmUs+spDynrRvhqX6HdwtoSfT7rnI58j4croW/Jg+rMCns5YncGMvyGXf4Kv4qBwpzVIdbH2zHrZhcNnpsizrui6KQi6PufhYmMFCtm1bFIUxRlbJTGEw7GA5i6KQD5F0xNcalyucSVWXiNQWR1/LE7jqF2Rqb/BVfFRu3lpXZpTXcX/7gi/rp0+f/uc//+lv/+lPf9rf2H9lG2PqupYLXMlbVH5IqpBt2yrnSony0XyK5/zIcuZ5Ps/Hx5HlFPLnVkq5lzdLQVKFUet5Ahd8Qe5lwTf4eEt9VMJFi0IqiqIoy1LeFXmeN00jb9qk2GHGIrUPPqtt27Zt8zzP89z+nOZHSVVV8qfvui7Z5zNlq3gC1/KCXMUbfBUflRuz1hYFecstXYobLi8vLy8vQ7caY9wCL1X4Iws526fbkeV025/lQ+REL5gjy+l+N5q8bHuxa56m8CpVo8uz+BM4spyzvSBDRpZz2fiS2osQP1hygMTpqTRGlLizjPoTuqSE/aG8M/91xhTSGzq0yLCsMeX09l9qNtrOcmbXs8Bd8xdVRAqcWnmSegK39IJc/A2+io/KMRKpeqaS3PM7rXT+Wm44s0Xqvy0Hd0uqkN5gsZlLOL6c1oKzp3aWM7XsvuzLb2R5EnwCN/OC7BJ4g48p5OIflTulWaqD6S7wZsPkpE1vZ0vayN1OZBWFTKEAI62lnFZqBU6tPCEbKyefQnARFAAAQBCzHgAAQBBBAQAABBEUAABAEEEBAAAEERQAAEAQQQEAAAQRFAAAQBBBAQAABBEUAABAEEEBAAAEERQAAEAQQQEAAAQRFAAAQBBBAQAABBEUAABAEEEBAAAEERQAAEAQQQEAAAQRFAAAQBBBAQAABBEUAABAEEEBAAAEERQAAEAQQQEAAAQRFAAAQBBBAQAABBEUAABAEEEBAAAEERQAAEAQQQEAAAT9f0prmQ0Up2RqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Info in <TCanvas::Print>: png file SR_2tag_Xtohh2000_COMB5_Keras_Dense_hist.png has been created\n"
     ]
    }
   ],
   "source": [
    "config = \"SR_2tag\"\n",
    "type_signal = \"Xtohh2000\"\n",
    "methodName = \"Keras_Dense\"\n",
    "sep = 0.934\n",
    "comb = \"COMB5\"\n",
    "pred, score = predict(config, type_signal, methodName, sep, comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05173677]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "score_s = [i for i in score if i > 0.934]\n",
    "score_b = [i for i in score if i <= 0.934]\n",
    "\n",
    "plt.figure(figsize=[10,8])\n",
    "plt.hist([score_s, score_b], color=['green', 'red'], bins=30)\n",
    "plt.xlabel(\"DNN Score\", fontsize=15)\n",
    "plt.ylabel(\"Frequency\", fontsize=15)\n",
    "plt.title('Real Data Prediction with DNN in '+config+\"_\"+type_signal, fontsize=20)\n",
    "plt.savefig(config+\"_\"+type_signal+\"_DNN_pred.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
