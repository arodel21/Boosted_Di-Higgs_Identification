{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>TMVA Classification Using Deep Neural Networks</center>\n",
    "\n",
    "In this notebook we still classify di-Higgs new data with Deep Neural Networks meethod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.14/04\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "from ROOT import TMVA, TTree\n",
    "\n",
    "ROOT.TMVA.Tools.Instance()\n",
    "## For PYMVA methods\n",
    "TMVA.PyMethodBase.PyInitialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter dataset by region.\n",
    "\n",
    "This function will let you filter your dataset by region. It's known that SR_1tag is very signal poor, while SR_2tag has a lot a signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_region(file, region, newfile):\n",
    "    oldfile = ROOT.TFile(file)\n",
    "    oldtree = oldfile.Nominal\n",
    "    newfile = ROOT.TFile(newfile,\"recreate\")\n",
    "    newtree = oldtree.CloneTree(0)\n",
    "    for entry in oldtree:\n",
    "        if (entry.m_region == region):\n",
    "            newtree.Fill()\n",
    "    \n",
    "    newtree.AutoSave()   \n",
    "    return newtree, newfile\n",
    "\n",
    "#Use as\n",
    "#tree, file = filter_region(\"data.root\", \"SR_1tag\", \"small.root\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare Factory and Input Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data.root has unlabeled data points (called data) and fakes points. For the background training we'll use only the fakes points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153148"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oldtree, oldfile = filter_region(\"data.root\", \"SR_1tag\", \"data_f.root\")\n",
    "\n",
    "newfile = ROOT.TFile(\"small.root\",\"recreate\")\n",
    "backgroundTreeB1 = oldtree.CloneTree(0)\n",
    "\n",
    "for entry in oldtree:\n",
    "    sample = entry.sample\n",
    "    reg = entry.m_region\n",
    "    if (sample == 'fakes'):\n",
    "        backgroundTreeB1.Fill()\n",
    "\n",
    "backgroundTreeB1.AutoSave()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************************************************\n",
      "*Tree    :Nominal   : Nominal                                                *\n",
      "*Entries :     2577 : Total =          255548 bytes  File  Size =     158982 *\n",
      "*        :          : Tree compression factor =   8.04                       *\n",
      "******************************************************************************\n",
      "*Br    0 :sample    : string                                                 *\n",
      "*Entries :     2577 : Total  Size=      26523 bytes  File Size  =       3320 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   6.89     *\n",
      "*............................................................................*\n",
      "*Br    1 :EventWeight : EventWeight/F                                        *\n",
      "*Entries :     2577 : Total  Size=      10995 bytes  One basket in memory    *\n",
      "*Baskets :        0 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    2 :EventNumber : EventNumber/l                                        *\n",
      "*Entries :     2577 : Total  Size=      21311 bytes  One basket in memory    *\n",
      "*Baskets :        0 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    3 :m_region  : string                                                 *\n",
      "*Entries :     2577 : Total  Size=      31691 bytes  File Size  =       2514 *\n",
      "*Baskets :        1 : Basket Size=      32000 bytes  Compression=   9.56     *\n",
      "*............................................................................*\n",
      "*Br    4 :m_FJNbtagJets : m_FJNbtagJets/I                                    *\n",
      "*Entries :     2577 : Total  Size=      11007 bytes  One basket in memory    *\n",
      "*Baskets :        0 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    5 :m_FJpt    : m_FJpt/F                                               *\n",
      "*Entries :     2577 : Total  Size=      10965 bytes  One basket in memory    *\n",
      "*Baskets :        0 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    6 :m_FJeta   : m_FJeta/F                                              *\n",
      "*Entries :     2577 : Total  Size=      10971 bytes  One basket in memory    *\n",
      "*Baskets :        0 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    7 :m_FJphi   : m_FJphi/F                                              *\n",
      "*Entries :     2577 : Total  Size=      10971 bytes  One basket in memory    *\n",
      "*Baskets :        0 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    8 :m_FJm     : m_FJm/F                                                *\n",
      "*Entries :     2577 : Total  Size=      10959 bytes  One basket in memory    *\n",
      "*Baskets :        0 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br    9 :m_DTpt    : m_DTpt/F                                               *\n",
      "*Entries :     2577 : Total  Size=      10965 bytes  One basket in memory    *\n",
      "*Baskets :        0 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   10 :m_DTeta   : m_DTeta/F                                              *\n",
      "*Entries :     2577 : Total  Size=      10971 bytes  One basket in memory    *\n",
      "*Baskets :        0 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   11 :m_DTphi   : m_DTphi/F                                              *\n",
      "*Entries :     2577 : Total  Size=      10971 bytes  One basket in memory    *\n",
      "*Baskets :        0 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   12 :m_DTm     : m_DTm/F                                                *\n",
      "*Entries :     2577 : Total  Size=      10959 bytes  One basket in memory    *\n",
      "*Baskets :        0 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   13 :m_dPhiFTwDT : m_dPhiFTwDT/F                                        *\n",
      "*Entries :     2577 : Total  Size=      10995 bytes  One basket in memory    *\n",
      "*Baskets :        0 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   14 :m_dRFJwDT : m_dRFJwDT/F                                            *\n",
      "*Entries :     2577 : Total  Size=      10983 bytes  One basket in memory    *\n",
      "*Baskets :        0 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   15 :m_dPhiDTwMET : m_dPhiDTwMET/F                                      *\n",
      "*Entries :     2577 : Total  Size=      11001 bytes  One basket in memory    *\n",
      "*Baskets :        0 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   16 :m_MET     : m_MET/F                                                *\n",
      "*Entries :     2577 : Total  Size=      10959 bytes  One basket in memory    *\n",
      "*Baskets :        0 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   17 :m_hhm     : m_hhm/F                                                *\n",
      "*Entries :     2577 : Total  Size=      10959 bytes  One basket in memory    *\n",
      "*Baskets :        0 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n",
      "*Br   18 :m_bbttpt  : m_bbttpt/F                                             *\n",
      "*Entries :     2577 : Total  Size=      10977 bytes  One basket in memory    *\n",
      "*Baskets :        0 : Basket Size=      32000 bytes  Compression=   1.00     *\n",
      "*............................................................................*\n"
     ]
    }
   ],
   "source": [
    "outputFile = ROOT.TFile.Open(\"Higgs_ClassificationOutput.root\", \"RECREATE\")\n",
    "\n",
    "# Factory\n",
    "factory = ROOT.TMVA.Factory(\"TMVA_Higgs_Classification\", outputFile,\n",
    "                      \"!V:ROC:!Silent:Color:!DrawProgressBar:AnalysisType=Classification\" )\n",
    "\n",
    "# Input data\n",
    "# We define now the input data file and we retrieve the ROOT TTree objects with the signal and background input events\n",
    "#signalTree1, inputFileS1 = filter_region(\"Xtohh1000.root\", \"SR_1tag\", \"Xtohh1000_f.root\")\n",
    "signalTree2, inputFileS2 = filter_region(\"Xtohh2000.root\", \"SR_1tag\", \"Xtohh2000_f.root\")\n",
    "backgroundTreeB2, inputFileB2 = filter_region(\"stop.root\", \"SR_1tag\", \"stop_f.root\")\n",
    "backgroundTreeB3, inputFileB3 = filter_region(\"ttbar.root\", \"SR_1tag\", \"ttbar_f.root\")\n",
    "backgroundTreeB4, inputFileB4 = filter_region(\"W+jets.root\", \"SR_1tag\", \"W+jets_f.root\")\n",
    "backgroundTreeB5, inputFileB5 = filter_region(\"Zee_221.root\", \"SR_1tag\", \"Zee_221_f.root\")\n",
    "backgroundTreeB6, inputFileB6 = filter_region(\"Ztautau_221.root\", \"SR_1tag\", \"Ztautau_221_f.root\")\n",
    "backgroundTreeB7, inputFileB7 = filter_region(\"ZZ_Pw.root\", \"SR_1tag\", \"ZZ_Pw_f.root\")\n",
    "\n",
    "backgroundTreeB1.Print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declare DataLoader(s)\n",
    "\n",
    "The next step is to declare the DataLoader class that deals with input data abd variables \n",
    "\n",
    "We add first the signal and background trees in the data loader and then we\n",
    "define the input variables that shall be used for the MVA training\n",
    "note that you may also use variable expressions, which can be parsed by TTree::Draw( \"expression\" )]\n",
    "\n",
    "We have two kinds of signals and for the training we have to use only one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSetInfo              : [dataset] : Added class \"Signal\"\n",
      "                         : Add Tree Nominal of type Signal with 9355 events\n",
      "DataSetInfo              : [dataset] : Added class \"Background\"\n",
      "                         : Add Tree Nominal of type Background with 2577 events\n",
      "                         : Add Tree Nominal of type Background with 127 events\n",
      "                         : Add Tree Nominal of type Background with 695 events\n",
      "                         : Add Tree Nominal of type Background with 1140 events\n",
      "                         : Add Tree Nominal of type Background with 275 events\n",
      "                         : Add Tree Nominal of type Background with 4403 events\n",
      "                         : Add Tree Nominal of type Background with 45 events\n"
     ]
    }
   ],
   "source": [
    "loader = ROOT.TMVA.DataLoader(\"dataset\")\n",
    "\n",
    "### global event weights per tree (see below for setting event-wise weights)\n",
    "signalWeight     = 1.0\n",
    "backgroundWeight = 1.0\n",
    "   \n",
    "### You can add an arbitrary number of signal or background trees\n",
    "#loader.AddSignalTree    ( signalTree1,     signalWeight     )\n",
    "loader.AddSignalTree    ( signalTree2,     signalWeight     )\n",
    "loader.AddBackgroundTree( backgroundTreeB1, backgroundWeight )\n",
    "loader.AddBackgroundTree( backgroundTreeB2, backgroundWeight )\n",
    "loader.AddBackgroundTree( backgroundTreeB3, backgroundWeight )\n",
    "loader.AddBackgroundTree( backgroundTreeB4, backgroundWeight )\n",
    "loader.AddBackgroundTree( backgroundTreeB5, backgroundWeight )\n",
    "loader.AddBackgroundTree( backgroundTreeB6, backgroundWeight )\n",
    "loader.AddBackgroundTree( backgroundTreeB7, backgroundWeight )\n",
    "\n",
    "not_cons = ['sample', 'EventWeight', 'EventNumber', 'm_region', 'm_FJNbtagJets', 'm_FJphi', 'm_FJeta', 'm_DTeta', 'm_DTphi']\n",
    "\n",
    "## Define input variables \n",
    "for branch in backgroundTreeB1.GetListOfBranches():\n",
    "    if branch.GetName() in not_cons:\n",
    "        continue\n",
    "    loader.AddVariable(branch.GetName())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dataset(s)\n",
    "\n",
    "Setup the DataLoader by splitting events in training and test samples. \n",
    "Here we use a random split and a fixed number of training and test events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply additional cuts on the signal and background samples (can be different)\n",
    "mycuts = ROOT.TCut(\"\")   ## for example: TCut mycuts = \"abs(var1)<0.5 && abs(var2-0.5)<1\";\n",
    "mycutb = ROOT.TCut(\"\")   ## for example: TCut mycutb = \"abs(var1)<0.5\";\n",
    "\n",
    "loader.PrepareTrainingAndTestTree(mycuts, mycutb,\n",
    "                                  \"nTrain_Signal=8000:nTrain_Background=8000:SplitMode=Random:\"\n",
    "                                   \"NormMode=NumEvents:!V\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, SGD\n",
    "#from keras.initializers import TruncatedNormal\n",
    "#from keras import initializations\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Reshape\n",
    "#from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                704       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 13,314\n",
      "Trainable params: 13,314\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, kernel_initializer='glorot_normal', activation='sigmoid', input_dim=10))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(64, kernel_initializer='glorot_normal', activation='relu'))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(64, kernel_initializer='glorot_normal', activation='relu'))\n",
    "model.add(Dense(64, kernel_initializer='glorot_normal', activation='relu'))\n",
    "model.add(Dense(2, kernel_initializer='glorot_uniform', activation='softmax'))\n",
    "\n",
    "# Set loss and optimizer\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['categorical_accuracy',])\n",
    "\n",
    "# Store model to file\n",
    "model.save('model_dense.h5')\n",
    "\n",
    "# Print summary of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ROOT.TMVA::MethodPyKeras object (\"Keras_Dense\") at 0xacd5b30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : Booking method: \u001b[1mKeras_Dense\u001b[0m\n",
      "                         : \n",
      "Keras_Dense              : [dataset] : Create Transformation \"G\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'm_FJpt' <---> Output : variable 'm_FJpt'\n",
      "                         : Input : variable 'm_FJm' <---> Output : variable 'm_FJm'\n",
      "                         : Input : variable 'm_DTpt' <---> Output : variable 'm_DTpt'\n",
      "                         : Input : variable 'm_DTm' <---> Output : variable 'm_DTm'\n",
      "                         : Input : variable 'm_dPhiFTwDT' <---> Output : variable 'm_dPhiFTwDT'\n",
      "                         : Input : variable 'm_dRFJwDT' <---> Output : variable 'm_dRFJwDT'\n",
      "                         : Input : variable 'm_dPhiDTwMET' <---> Output : variable 'm_dPhiDTwMET'\n",
      "                         : Input : variable 'm_MET' <---> Output : variable 'm_MET'\n",
      "                         : Input : variable 'm_hhm' <---> Output : variable 'm_hhm'\n",
      "                         : Input : variable 'm_bbttpt' <---> Output : variable 'm_bbttpt'\n",
      "                         : Load model from file: model_dense.h5\n"
     ]
    }
   ],
   "source": [
    "factory.BookMethod(loader, ROOT.TMVA.Types.kPyKeras, 'Keras_Dense',\n",
    "        'H:!V:VarTransform=G:FilenameModel=model_dense.h5:'+\\\n",
    "        'NumEpochs=10:BatchSize=16:TriesEarlyStopping=10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrea/anaconda3/lib/python3.5/site-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16000 samples, validate on 2617 samples\n",
      "Epoch 1/10\n",
      "16000/16000 [==============================] - 4s 262us/step - loss: 0.3749 - categorical_accuracy: 0.8373 - val_loss: 0.3406 - val_categorical_accuracy: 0.8586\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.34062, saving model to dataset/weights/TrainedModel_Keras_Dense.h5\n",
      "Epoch 2/10\n",
      "16000/16000 [==============================] - 4s 240us/step - loss: 0.3050 - categorical_accuracy: 0.8697 - val_loss: 0.3032 - val_categorical_accuracy: 0.8758\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.34062 to 0.30318, saving model to dataset/weights/TrainedModel_Keras_Dense.h5\n",
      "Epoch 3/10\n",
      "16000/16000 [==============================] - 3s 204us/step - loss: 0.2856 - categorical_accuracy: 0.8783 - val_loss: 0.3088 - val_categorical_accuracy: 0.8674\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.30318\n",
      "Epoch 4/10\n",
      "16000/16000 [==============================] - 3s 206us/step - loss: 0.2742 - categorical_accuracy: 0.8887 - val_loss: 0.3285 - val_categorical_accuracy: 0.8674\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30318\n",
      "Epoch 5/10\n",
      "16000/16000 [==============================] - 3s 207us/step - loss: 0.2701 - categorical_accuracy: 0.8877 - val_loss: 0.2853 - val_categorical_accuracy: 0.8808\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.30318 to 0.28527, saving model to dataset/weights/TrainedModel_Keras_Dense.h5\n",
      "Epoch 6/10\n",
      "16000/16000 [==============================] - 3s 211us/step - loss: 0.2683 - categorical_accuracy: 0.8866 - val_loss: 0.2887 - val_categorical_accuracy: 0.8728\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.28527\n",
      "Epoch 7/10\n",
      "16000/16000 [==============================] - 4s 222us/step - loss: 0.2656 - categorical_accuracy: 0.8881 - val_loss: 0.2728 - val_categorical_accuracy: 0.8827\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.28527 to 0.27278, saving model to dataset/weights/TrainedModel_Keras_Dense.h5\n",
      "Epoch 8/10\n",
      "16000/16000 [==============================] - 4s 262us/step - loss: 0.2638 - categorical_accuracy: 0.8898 - val_loss: 0.2875 - val_categorical_accuracy: 0.8777\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.27278\n",
      "Epoch 9/10\n",
      "16000/16000 [==============================] - 4s 233us/step - loss: 0.2611 - categorical_accuracy: 0.8904 - val_loss: 0.2695 - val_categorical_accuracy: 0.8854\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.27278 to 0.26948, saving model to dataset/weights/TrainedModel_Keras_Dense.h5\n",
      "Epoch 10/10\n",
      "16000/16000 [==============================] - 4s 249us/step - loss: 0.2616 - categorical_accuracy: 0.8896 - val_loss: 0.2740 - val_categorical_accuracy: 0.8804\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.26948\n",
      "Factory                  : \u001b[1mTrain all methods\u001b[0m\n",
      "DataSetFactory           : [dataset] : Number of events in input trees\n",
      "                         : \n",
      "                         : \n",
      "                         : Number of training and testing events\n",
      "                         : ---------------------------------------------------------------------------\n",
      "                         : Signal     -- training events            : 8000\n",
      "                         : Signal     -- testing events             : 1355\n",
      "                         : Signal     -- training and testing events: 9355\n",
      "                         : Background -- training events            : 8000\n",
      "                         : Background -- testing events             : 1262\n",
      "                         : Background -- training and testing events: 9262\n",
      "                         : \n",
      "DataSetInfo              : Correlation matrix (Signal):\n",
      "                         : ---------------------------------------------------------------------------------------------------------\n",
      "                         :                m_FJpt   m_FJm  m_DTpt   m_DTm m_dPhiFTwDT m_dRFJwDT m_dPhiDTwMET   m_MET   m_hhm m_bbttpt\n",
      "                         :       m_FJpt:  +1.000  +0.291  +0.273  +0.109      -0.086    -0.591       -0.003  +0.289  +0.235   +0.587\n",
      "                         :        m_FJm:  +0.291  +1.000  +0.147  +0.061      +0.040    -0.006       -0.002  +0.144  +0.349   +0.108\n",
      "                         :       m_DTpt:  +0.273  +0.147  +1.000  +0.608      +0.068    -0.251       -0.007  -0.408  +0.670   -0.349\n",
      "                         :        m_DTm:  +0.109  +0.061  +0.608  +1.000      +0.048    -0.031       +0.001  -0.297  +0.544   -0.267\n",
      "                         :  m_dPhiFTwDT:  -0.086  +0.040  +0.068  +0.048      +1.000    +0.593       +0.029  -0.054  +0.033   -0.612\n",
      "                         :    m_dRFJwDT:  -0.591  -0.006  -0.251  -0.031      +0.593    +1.000       +0.016  -0.257  +0.205   -0.600\n",
      "                         : m_dPhiDTwMET:  -0.003  -0.002  -0.007  +0.001      +0.029    +0.016       +1.000  +0.009  -0.007   -0.022\n",
      "                         :        m_MET:  +0.289  +0.144  -0.408  -0.297      -0.054    -0.257       +0.009  +1.000  -0.414   +0.480\n",
      "                         :        m_hhm:  +0.235  +0.349  +0.670  +0.544      +0.033    +0.205       -0.007  -0.414  +1.000   -0.226\n",
      "                         :     m_bbttpt:  +0.587  +0.108  -0.349  -0.267      -0.612    -0.600       -0.022  +0.480  -0.226   +1.000\n",
      "                         : ---------------------------------------------------------------------------------------------------------\n",
      "DataSetInfo              : Correlation matrix (Background):\n",
      "                         : ---------------------------------------------------------------------------------------------------------\n",
      "                         :                m_FJpt   m_FJm  m_DTpt   m_DTm m_dPhiFTwDT m_dRFJwDT m_dPhiDTwMET   m_MET   m_hhm m_bbttpt\n",
      "                         :       m_FJpt:  +1.000  +0.121  +0.439  +0.149      +0.008    -0.022       -0.009  +0.526  +0.562   +0.515\n",
      "                         :        m_FJm:  +0.121  +1.000  +0.085  +0.085      -0.022    -0.020       -0.010  +0.083  +0.107   +0.068\n",
      "                         :       m_DTpt:  +0.439  +0.085  +1.000  +0.565      +0.147    +0.103       -0.017  -0.096  +0.592   -0.130\n",
      "                         :        m_DTm:  +0.149  +0.085  +0.565  +1.000      +0.115    +0.108       -0.001  -0.116  +0.347   -0.163\n",
      "                         :  m_dPhiFTwDT:  +0.008  -0.022  +0.147  +0.115      +1.000    +0.668       -0.000  -0.020  +0.135   -0.695\n",
      "                         :    m_dRFJwDT:  -0.022  -0.020  +0.103  +0.108      +0.668    +1.000       +0.017  -0.063  +0.598   -0.486\n",
      "                         : m_dPhiDTwMET:  -0.009  -0.010  -0.017  -0.001      -0.000    +0.017       +1.000  -0.012  +0.003   -0.002\n",
      "                         :        m_MET:  +0.526  +0.083  -0.096  -0.116      -0.020    -0.063       -0.012  +1.000  +0.128   +0.465\n",
      "                         :        m_hhm:  +0.562  +0.107  +0.592  +0.347      +0.135    +0.598       +0.003  +0.128  +1.000   +0.083\n",
      "                         :     m_bbttpt:  +0.515  +0.068  -0.130  -0.163      -0.695    -0.486       -0.002  +0.465  +0.083   +1.000\n",
      "                         : ---------------------------------------------------------------------------------------------------------\n",
      "DataSetFactory           : [dataset] :  \n",
      "                         : \n",
      "Factory                  : [dataset] : Create Transformation \"I\" with events from all classes.\n",
      "                         : \n",
      "                         : Transformation, Variable selection : \n",
      "                         : Input : variable 'm_FJpt' <---> Output : variable 'm_FJpt'\n",
      "                         : Input : variable 'm_FJm' <---> Output : variable 'm_FJm'\n",
      "                         : Input : variable 'm_DTpt' <---> Output : variable 'm_DTpt'\n",
      "                         : Input : variable 'm_DTm' <---> Output : variable 'm_DTm'\n",
      "                         : Input : variable 'm_dPhiFTwDT' <---> Output : variable 'm_dPhiFTwDT'\n",
      "                         : Input : variable 'm_dRFJwDT' <---> Output : variable 'm_dRFJwDT'\n",
      "                         : Input : variable 'm_dPhiDTwMET' <---> Output : variable 'm_dPhiDTwMET'\n",
      "                         : Input : variable 'm_MET' <---> Output : variable 'm_MET'\n",
      "                         : Input : variable 'm_hhm' <---> Output : variable 'm_hhm'\n",
      "                         : Input : variable 'm_bbttpt' <---> Output : variable 'm_bbttpt'\n",
      "TFHandler_Factory        :     Variable            Mean            RMS    [        Min            Max ]\n",
      "                         : -------------------------------------------------------------------------------\n",
      "                         :       m_FJpt:        721.73        211.90   [        254.51        2069.4 ]\n",
      "                         :        m_FJm:    1.0222e+05        78912.   [     -0.015625    7.2287e+05 ]\n",
      "                         :       m_DTpt:        554.34        150.79   [        308.41        1822.9 ]\n",
      "                         :        m_DTm:    1.5281e+05        42953.   [        38735.    5.3948e+05 ]\n",
      "                         :  m_dPhiFTwDT:        2.9727       0.27018   [     0.0092845        3.1416 ]\n",
      "                         :    m_dRFJwDT:        3.1828       0.33304   [        1.0171        4.8621 ]\n",
      "                         : m_dPhiDTwMET:     0.0010954       0.31277   [       -1.1187        1.0494 ]\n",
      "                         :        m_MET:        211.02        159.97   [        10.022        1264.3 ]\n",
      "                         :        m_hhm:        1476.4        379.08   [        426.11        4598.2 ]\n",
      "                         :     m_bbttpt:        242.39        196.35   [        1.0169        2070.5 ]\n",
      "                         : -------------------------------------------------------------------------------\n",
      "                         : Ranking input variables (method unspecific)...\n",
      "IdTransformation         : Ranking result (top variable is best ranked)\n",
      "                         : -------------------------------------\n",
      "                         : Rank : Variable     : Separation\n",
      "                         : -------------------------------------\n",
      "                         :    1 : m_hhm        : 4.051e-01\n",
      "                         :    2 : m_FJpt       : 3.971e-01\n",
      "                         :    3 : m_FJm        : 3.023e-01\n",
      "                         :    4 : m_MET        : 1.976e-01\n",
      "                         :    5 : m_DTpt       : 1.524e-01\n",
      "                         :    6 : m_bbttpt     : 1.376e-01\n",
      "                         :    7 : m_dPhiDTwMET : 6.633e-02\n",
      "                         :    8 : m_dRFJwDT    : 1.366e-02\n",
      "                         :    9 : m_DTm        : 7.696e-03\n",
      "                         :   10 : m_dPhiFTwDT  : 5.153e-03\n",
      "                         : -------------------------------------\n",
      "Factory                  : Train method: Keras_Dense for Classification\n",
      "                         : \n",
      "                         : \n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \u001b[1mH e l p   f o r   M V A   m e t h o d   [ Keras_Dense ] :\u001b[0m\n",
      "                         : \n",
      "                         : Keras is a high-level API for the Theano and Tensorflow packages.\n",
      "                         : This method wraps the training and predictions steps of the Keras\n",
      "                         : Python package for TMVA, so that dataloading, preprocessing and\n",
      "                         : evaluation can be done within the TMVA system. To use this Keras\n",
      "                         : interface, you have to generate a model with Keras first. Then,\n",
      "                         : this model can be loaded and trained in TMVA.\n",
      "                         : \n",
      "                         : \n",
      "                         : <Suppress this message by specifying \"!H\" in the booking option>\n",
      "                         : \u001b[1m================================================================\u001b[0m\n",
      "                         : \n",
      "                         : Preparing the Gaussian transformation...\n",
      "TFHandler_Keras_Dense    :     Variable            Mean            RMS    [        Min            Max ]\n",
      "                         : -------------------------------------------------------------------------------\n",
      "                         :       m_FJpt:     0.0039970       0.99941   [       -3.3182        5.7307 ]\n",
      "                         :        m_FJm:     0.0041336       0.99955   [       -3.0857        5.7307 ]\n",
      "                         :       m_DTpt:     0.0039094       0.99874   [       -3.3182        5.7307 ]\n",
      "                         :        m_DTm:     0.0031967       0.99971   [       -3.4491        5.7307 ]\n",
      "                         :  m_dPhiFTwDT:     0.0042923        1.0005   [       -3.3181        5.7307 ]\n",
      "                         :    m_dRFJwDT:     0.0042177        1.0003   [       -3.3178        5.7307 ]\n",
      "                         : m_dPhiDTwMET:     0.0040478       0.99895   [       -3.3179        5.7307 ]\n",
      "                         :        m_MET:     0.0041849        1.0002   [       -3.2613        5.7307 ]\n",
      "                         :        m_hhm:     0.0047387        1.0027   [       -3.3182        5.7307 ]\n",
      "                         :     m_bbttpt:     0.0041957        1.0001   [       -3.3182        5.7307 ]\n",
      "                         : -------------------------------------------------------------------------------\n",
      "                         : Option SaveBestOnly: Only model weights with smallest validation loss will be stored\n",
      "                         : Option TriesEarlyStopping: Training will stop after 10 number of epochs with no improvement of validation loss\n",
      "                         : Elapsed time for training with 16000 events: 38.4 sec         \n",
      "                         : Creating xml weight file: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_Keras_Dense.weights.xml\u001b[0m\n",
      "                         : Creating standalone class: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_Keras_Dense.class.C\u001b[0m\n",
      "Factory                  : Training finished\n",
      "                         : \n",
      "                         : Ranking input variables (method specific)...\n",
      "                         : No variable ranking supplied by classifier: Keras_Dense\n",
      "Factory                  : === Destroy and recreate all methods via weight files for testing ===\n",
      "                         : \n",
      "                         : Reading weight file: \u001b[0;36mdataset/weights/TMVA_Higgs_Classification_Keras_Dense.weights.xml\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "factory.TrainAllMethods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test  Model\n",
    "\n",
    "Here we test all methods using the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mTest all methods\u001b[0m\n",
      "Factory                  : Test method: Keras_Dense for Classification performance\n",
      "                         : \n",
      "                         : Load model from file: dataset/weights/TrainedModel_Keras_Dense.h5\n"
     ]
    }
   ],
   "source": [
    "factory.TestAllMethods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model\n",
    "\n",
    "Here we evaluate all methods and compare their performances, computing efficiencies, ROC curves etc.. using both training and tetsing data sets. Several histograms are produced which can be examined with the TMVAGui or directly using the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory                  : \u001b[1mEvaluate all methods\u001b[0m\n",
      "Factory                  : Evaluate classifier: Keras_Dense\n",
      "                         : \n",
      "TFHandler_Keras_Dense    :     Variable            Mean            RMS    [        Min            Max ]\n",
      "                         : -------------------------------------------------------------------------------\n",
      "                         :       m_FJpt:      0.037000       0.98487   [       -3.0548        5.7307 ]\n",
      "                         :        m_FJm:     0.0068906       0.99347   [       -3.0857        3.7585 ]\n",
      "                         :       m_DTpt:      0.035097        1.0143   [       -3.1073        5.7307 ]\n",
      "                         :        m_DTm:      0.029885        1.0213   [       -3.0739        3.3749 ]\n",
      "                         :  m_dPhiFTwDT:     0.0064770        1.0064   [       -3.1209        5.7307 ]\n",
      "                         :    m_dRFJwDT:      0.016210        1.0022   [       -3.1742        3.2877 ]\n",
      "                         : m_dPhiDTwMET:     -0.025397       0.98217   [       -3.0694        3.8670 ]\n",
      "                         :        m_MET:      0.034680        1.0065   [       -3.0182        5.7307 ]\n",
      "                         :        m_hhm:      0.054248        1.0041   [       -2.9976        5.7307 ]\n",
      "                         :     m_bbttpt:      0.030650       0.98907   [       -3.0619        5.7307 ]\n",
      "                         : -------------------------------------------------------------------------------\n",
      "Keras_Dense              : [dataset] : Loop over test events and fill histograms with classifier response...\n",
      "                         : \n",
      "TFHandler_Keras_Dense    :     Variable            Mean            RMS    [        Min            Max ]\n",
      "                         : -------------------------------------------------------------------------------\n",
      "                         :       m_FJpt:      0.037000       0.98487   [       -3.0548        5.7307 ]\n",
      "                         :        m_FJm:     0.0068906       0.99347   [       -3.0857        3.7585 ]\n",
      "                         :       m_DTpt:      0.035097        1.0143   [       -3.1073        5.7307 ]\n",
      "                         :        m_DTm:      0.029885        1.0213   [       -3.0739        3.3749 ]\n",
      "                         :  m_dPhiFTwDT:     0.0064770        1.0064   [       -3.1209        5.7307 ]\n",
      "                         :    m_dRFJwDT:      0.016210        1.0022   [       -3.1742        3.2877 ]\n",
      "                         : m_dPhiDTwMET:     -0.025397       0.98217   [       -3.0694        3.8670 ]\n",
      "                         :        m_MET:      0.034680        1.0065   [       -3.0182        5.7307 ]\n",
      "                         :        m_hhm:      0.054248        1.0041   [       -2.9976        5.7307 ]\n",
      "                         :     m_bbttpt:      0.030650       0.98907   [       -3.0619        5.7307 ]\n",
      "                         : -------------------------------------------------------------------------------\n",
      "                         : \n",
      "                         : Evaluation results ranked by best signal efficiency and purity (area)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet       MVA                       \n",
      "                         : Name:         Method:          ROC-integ\n",
      "                         : dataset       Keras_Dense    : 0.955\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "                         : Testing efficiency compared to training efficiency (overtraining check)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) \n",
      "                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   \n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : dataset              Keras_Dense    : 0.472 (0.525)       0.864 (0.883)      0.977 (0.980)\n",
      "                         : -------------------------------------------------------------------------------------------------------------------\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TestTree' with 2617 events\n",
      "                         : \n",
      "Dataset:dataset          : Created tree 'TrainTree' with 16000 events\n",
      "                         : \n",
      "Factory                  : \u001b[1mThank you for using TMVA!\u001b[0m\n",
      "                         : \u001b[1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "factory.EvaluateAllMethods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot ROC Curve\n",
    "We enable JavaScript visualisation for the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c1 = factory.GetROCCurve(loader)\n",
    "c1.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "* Aclarar cómo afecta el peso al modelo.\n",
    "* Clasificar los puntos de datos.\n",
    "* Aclarar cómo se va a medir la performance de los modelos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
